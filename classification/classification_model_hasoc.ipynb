{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.0.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)  \n",
    "    torch.manual_seed(seed_value)  \n",
    "    random.seed(seed_value)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  \n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/ubuntu/gaurav/in/fire/code-mixed-enta/classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA_TW630</td>\n",
       "      <td>@USER Avaru romba varshan munnadi eh retire aa...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA_TW3041</td>\n",
       "      <td>@USER Ungotha yaru unaku therium ungoppan munj...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA_TW6151</td>\n",
       "      <td>@USER Athu thaan avan thannoda instagram id la...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA_TW3291</td>\n",
       "      <td>RT @USER Nee Onnu pannu....Vijay poolu ah Oomb...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA_TW2722</td>\n",
       "      <td>@USER hater of Ajith nu hater of Ajith tha da ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                  1    2\n",
       "0   TA_TW630  @USER Avaru romba varshan munnadi eh retire aa...  NOT\n",
       "1  TA_TW3041  @USER Ungotha yaru unaku therium ungoppan munj...  OFF\n",
       "2  TA_TW6151  @USER Athu thaan avan thannoda instagram id la...  NOT\n",
       "3  TA_TW3291  RT @USER Nee Onnu pannu....Vijay poolu ah Oomb...  OFF\n",
       "4  TA_TW2722  @USER hater of Ajith nu hater of Ajith tha da ...  OFF"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(path/'../hasoc_task_2/Tamil-Codemixed_offensive_data_Training-Tweet-HL.xlsx', header=None)\n",
    "df.dropna(inplace=True)\n",
    "df.replace(to_replace='not', value='NOT', inplace=True)\n",
    "df.replace(to_replace='OFf', value='OFF', inplace=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NOT': 2020, 'OFF': 1980})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA_TW630</td>\n",
       "      <td>@USER Avaru romba varshan munnadi eh retire aa...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA_TW3041</td>\n",
       "      <td>@USER Ungotha yaru unaku therium ungoppan munj...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA_TW6151</td>\n",
       "      <td>@USER Athu thaan avan thannoda instagram id la...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA_TW3291</td>\n",
       "      <td>RT @USER Nee Onnu pannu....Vijay poolu ah Oomb...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA_TW2722</td>\n",
       "      <td>@USER hater of Ajith nu hater of Ajith tha da ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                  1    2\n",
       "0   TA_TW630  @USER Avaru romba varshan munnadi eh retire aa...  NOT\n",
       "1  TA_TW3041  @USER Ungotha yaru unaku therium ungoppan munj...  OFF\n",
       "2  TA_TW6151  @USER Athu thaan avan thannoda instagram id la...  NOT\n",
       "3  TA_TW3291  RT @USER Nee Onnu pannu....Vijay poolu ah Oomb...  OFF\n",
       "4  TA_TW2722  @USER hater of Ajith nu hater of Ajith tha da ...  OFF"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = int(0.8*len(df))\n",
    "df_train = df.iloc[:cutoff]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>TA_TW2000</td>\n",
       "      <td>@USER Semaya irukku D chellam plz dm va 7.9.in...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>TA_TW648</td>\n",
       "      <td>@USER Enaku unnoda Feeling puriyuthu abi Try p...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>TA_HL481</td>\n",
       "      <td>itha losliya nu solitingale</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>TA_TW1950</td>\n",
       "      <td>@USER nee yaruda komali avana sona unaku kovam...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>TA_HL186</td>\n",
       "      <td>ama evalunga panra setaikku nama answer pannan...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                  1    2\n",
       "3200  TA_TW2000  @USER Semaya irukku D chellam plz dm va 7.9.in...  OFF\n",
       "3201   TA_TW648  @USER Enaku unnoda Feeling puriyuthu abi Try p...  NOT\n",
       "3202   TA_HL481                        itha losliya nu solitingale  NOT\n",
       "3203  TA_TW1950  @USER nee yaruda komali avana sona unaku kovam...  OFF\n",
       "3204   TA_HL186  ama evalunga panra setaikku nama answer pannan...  NOT"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = df.iloc[cutoff:]\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA_TW15946</td>\n",
       "      <td>Take it this thevidiya Kandipa indha page admi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA_TW10175</td>\n",
       "      <td>enga veetla itha nadakum Athum oru varushama t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA_TW15947</td>\n",
       "      <td>Indha Sallli Punda, Dummy Pundalam Orama Iruka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA_TW15174</td>\n",
       "      <td>Juriya poola tier 1 la umburan tha kulla punda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA_TW15182</td>\n",
       "      <td>Kullans lam umba therila Loosu kuthi maari umb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1\n",
       "0  TA_TW15946  Take it this thevidiya Kandipa indha page admi...\n",
       "1  TA_TW10175  enga veetla itha nadakum Athum oru varushama t...\n",
       "2  TA_TW15947  Indha Sallli Punda, Dummy Pundalam Orama Iruka...\n",
       "3  TA_TW15174  Juriya poola tier 1 la umburan tha kulla punda...\n",
       "4  TA_TW15182  Kullans lam umba therila Loosu kuthi maari umb..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../hasoc_task_2/Tamil_hasoc_tanglish_test_without_labels.tsv', sep='\\t', header=None)\n",
    "df_test.dropna(inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 3), (800, 3), (940, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NOT': 1633, 'OFF': 1567})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NOT': 387, 'OFF': 413})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_valid[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.concat([df_train, df_valid])\n",
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [2]\n",
    "text_cols = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_all_caps(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = replace_all_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def handle_upper_case_first_letter(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = deal_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def lower_case_everything(t: str) -> str:\n",
    "    return t.lower().replace('@user', '').replace('#tag ', '').replace('rt ', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMixedTamilTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(path/\"../tokenizer/taen_spm.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/taen_spm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxpad',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '.',\n",
       " ',',\n",
       " '▁',\n",
       " 's',\n",
       " 'a',\n",
       " '=\"',\n",
       " 'in',\n",
       " 'doc',\n",
       " 't',\n",
       " 'il',\n",
       " 'i']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8,000 is the vocab size that we chose in sentencepiece\n",
    "taen_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lang='taen', tok_func=CodeMixedTamilTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_rules.append(lower_case_everything)\n",
    "tokenizer.pre_rules.append(handle_all_caps)\n",
    "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep'],\n",
       " [<function fastai.text.transform.fix_html>,\n",
       "  <function fastai.text.transform.replace_rep>,\n",
       "  <function fastai.text.transform.replace_wrep>,\n",
       "  <function fastai.text.transform.spec_add_spaces>,\n",
       "  <function fastai.text.transform.rm_useless_spaces>,\n",
       "  <function __main__.lower_case_everything>,\n",
       "  <function __main__.handle_all_caps>,\n",
       "  <function __main__.handle_upper_case_first_letter>],\n",
       " [<function fastai.text.transform.replace_all_caps>,\n",
       "  <function fastai.text.transform.deal_caps>])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁tell▁me▁about▁tour▁self,▁mujhe▁jaanna▁hai'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.process_all(['Tell me about TOUR self, mujhe jaanna hai'])\n",
    "''.join(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=taen_vocab, label_cols=label_cols, text_cols=text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁eri ku ra ▁u h ▁da ▁the vid iya ▁pa iya le ▁x x bo s ▁at hu ▁tha an ▁avan ▁than n oda ▁in s ta gram ▁id ▁la ye ▁po du ▁iru kan e ▁vijay ▁do u ble ▁bod y ▁endu ▁un aku ▁it ha ▁vid a ▁ke val ama ▁ena ▁ven um ▁aa ▁tan e ▁ne nga ▁parthu ▁ra ▁x x bo s ▁ne e ▁on nu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁un ▁ dr ess ▁ um ▁ path ave ▁ pathi tu ▁varu th u . ▁x x bo s ▁nan um ▁un ga ▁f r nd ▁li st ▁la ▁iru ku ra tha ▁nin a chu ▁ro mba ▁pro ud ▁ ah ▁f e el ▁pan ren ▁x x bo s ▁br o ▁avan ▁oru ▁du m my ▁br o ▁fi rs t ▁on nu ▁sol lu van ▁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>x bo s ▁ ippa ▁mattu n ▁enna ▁pann adhu ▁theri yam aya ▁po edu chu ▁mutt al ugal a ▁x x bo s ▁de i ▁sang i ▁pun da ▁ma van e ▁ne e ▁co w ▁ ook ura ▁ xxunk ▁t ag ▁ uku ▁sun n iya ▁so op ura ▁w or k ▁mat um ▁pa aru ▁x x bo s ▁aam een ▁aam een ▁ya ▁ra bbu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bo s ▁un may ai na ▁sam ba vam ▁dha ▁men tal ▁ko o thi . ▁po i ▁goo gle ▁panni ▁pa aru ▁ney veli ▁is su e ▁va ▁x x bo s ▁dai ▁un ga ▁tha la ▁ bike ▁ra c er ▁ ah ▁iru tu ▁man go thal aye ▁doo p ▁po ta ▁pun da ▁thay oli ▁dhan a ▁x x bo s ▁pa it iyam ▁mari ▁iru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ap avin gl a . . . ▁it hu ▁enna da ▁surya ku ▁van dha ▁so than ai ▁ xxrep ▁4 ▁ . ▁up dat e ▁app ▁to ▁vi e w ▁x x bo s ▁sonna ▁pun da ▁ne e ▁katha ra tha ▁pa akal aam ▁nu ▁vant ha ▁da ▁mun da ▁ko o thi ▁ xxunk ▁t ag ▁ xxunk ▁t ag ▁ xxunk ▁t ag ▁x x bo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (3200 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁avar u ▁ro mba ▁var shan ▁munn adi ▁e h ▁re ti re ▁aa y itar u ▁nu ▁ne nai chen ▁ xxrep ▁4 ▁ . ▁for m ▁la ▁irukk a ▁app o ve ▁aa ganum ▁sol l itu ▁iru par u ▁ xxunk ▁t ag,▁x x bo s ▁un go tha ▁yar u ▁un aku ▁theri um ▁un go ppan ▁mun ji ▁pat hu ▁eri ku ra ▁u h ▁da ▁the vid iya ▁pa iya le,▁x x bo s ▁at hu ▁tha an ▁avan ▁than n oda ▁in s ta gram ▁id ▁la ye ▁po du ▁iru kan e ▁vijay ▁do u ble ▁bod y ▁endu ▁un aku ▁it ha ▁vid a ▁ke val ama ▁ena ▁ven um ▁aa ▁tan e ▁ne nga ▁parthu ▁ra,▁x x bo s ▁ne e ▁on nu ▁pann u ▁ xxrep ▁4 ▁ . ▁vijay ▁poo lu ▁ ah ▁o om bur ath a ▁niru th ittu ▁app uku tt y ▁ oda ▁poo lu ▁ ah ▁o o mba ▁sta pan nu . . . y enna ▁avan ▁dhan a ▁periya ▁a ctor ▁un ga ▁aj ith ▁ ah ▁vid a . . . ▁awar d ▁iru k ur avan ▁poo lu ▁ ah ▁dhan ▁ ish tam ▁ ah ▁o o mbu va ▁ne e ▁ xxrep ▁4 ▁ . ▁po ▁ national ▁awar d ▁dhan ▁periya ▁awar d ▁ xxrep ▁4 ▁ . ▁po i ▁app u ▁kutt y ▁ ah ▁o o mbu,▁x x bo s ▁ha ter ▁of ▁aj ith ▁nu ▁ha ter ▁of ▁aj ith ▁tha ▁da ▁po du vai nga ▁en ▁chi p su ▁e po ▁viv e gam ▁un der rat ed ▁mo vi e ▁son ing lo ▁a po va e ▁un ga ▁moola i ▁pun dai ▁ pathi ▁theri th u ▁ gro\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁se may a ▁irukk u ▁d ▁ch ellam ▁p l z ▁d m ▁va ▁7 . 9 . in ch ▁poo lu ▁sum ma ▁eng i ▁tha vi kku ren,▁x x bo s ▁ena ku ▁unn oda ▁f ee ling ▁puri yu th u ▁ab i ▁t ry ▁pann u ▁athan ▁naan ▁un aku ▁solla ▁muti y um ▁o . k ▁un ga ▁br o ▁ku ▁mar ri ag e ▁ai du cha,▁x x bo s ▁it ha ▁lo s l iya ▁nu ▁sol it in gale,▁x x bo s ▁ne e ▁yar uda ▁ko mali ▁avan a ▁son a ▁un aku ▁ko vam ▁varu dhu ▁d n v ▁go un der ▁pan gali ▁ ah ?,▁x x bo s ▁ ama ▁e val ung a ▁pan ra ▁se tai kku ▁nam a ▁an s wer ▁pann anu ma ▁ver a ▁eth ava th u ▁vel a ▁e runth a ▁paru nga ▁pon ga\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (940 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁tak e ▁it ▁thi s ▁the vid iya ▁kan di pa ▁ind ha ▁pa ge ▁ad min ▁oru ▁mu tu al ▁pun da ▁vijay ▁f an ▁ha ▁dhan ▁eru pan,▁x x bo s ▁eng a ▁veet la ▁it ha ▁nad akum ▁a thum ▁oru ▁varu sha ma ▁tha an ▁in tha ▁te ch nic ▁us e ▁pann ren ▁ser io us ly ▁it ▁w or ks,▁x x bo s ▁ind ha ▁sal lli ▁pun da , ▁du m my ▁pun dal am ▁or ama ▁iru kan um . . . ▁in ga ▁ xxunk ▁t ag ▁sa tham ▁mat um ▁tha an ▁iru kan um ▁ xxunk ▁t ag,▁x x bo s ▁ju riya ▁poo la ▁ti er ▁1 ▁la ▁ um bur an ▁tha ▁kull a ▁pun dai ▁o ol u ▁ ook uth u ▁pa aru,▁x x bo s ▁kull ans ▁ lam ▁u mba ▁theri la ▁lo osu ▁ku thi ▁ma ari ▁u mba ▁ven d iyath a ▁saman tha ▁pun da il aye ▁illa ▁athan ▁kull an\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(8000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6d96bcbd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (3200 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁avar u ▁ro mba ▁var shan ▁munn adi ▁e h ▁re ti re ▁aa y itar u ▁nu ▁ne nai chen ▁ xxrep ▁4 ▁ . ▁for m ▁la ▁irukk a ▁app o ve ▁aa ganum ▁sol l itu ▁iru par u ▁ xxunk ▁t ag,▁x x bo s ▁un go tha ▁yar u ▁un aku ▁theri um ▁un go ppan ▁mun ji ▁pat hu ▁eri ku ra ▁u h ▁da ▁the vid iya ▁pa iya le,▁x x bo s ▁at hu ▁tha an ▁avan ▁than n oda ▁in s ta gram ▁id ▁la ye ▁po du ▁iru kan e ▁vijay ▁do u ble ▁bod y ▁endu ▁un aku ▁it ha ▁vid a ▁ke val ama ▁ena ▁ven um ▁aa ▁tan e ▁ne nga ▁parthu ▁ra,▁x x bo s ▁ne e ▁on nu ▁pann u ▁ xxrep ▁4 ▁ . ▁vijay ▁poo lu ▁ ah ▁o om bur ath a ▁niru th ittu ▁app uku tt y ▁ oda ▁poo lu ▁ ah ▁o o mba ▁sta pan nu . . . y enna ▁avan ▁dhan a ▁periya ▁a ctor ▁un ga ▁aj ith ▁ ah ▁vid a . . . ▁awar d ▁iru k ur avan ▁poo lu ▁ ah ▁dhan ▁ ish tam ▁ ah ▁o o mbu va ▁ne e ▁ xxrep ▁4 ▁ . ▁po ▁ national ▁awar d ▁dhan ▁periya ▁awar d ▁ xxrep ▁4 ▁ . ▁po i ▁app u ▁kutt y ▁ ah ▁o o mbu,▁x x bo s ▁ha ter ▁of ▁aj ith ▁nu ▁ha ter ▁of ▁aj ith ▁tha ▁da ▁po du vai nga ▁en ▁chi p su ▁e po ▁viv e gam ▁un der rat ed ▁mo vi e ▁son ing lo ▁a po va e ▁un ga ▁moola i ▁pun dai ▁ pathi ▁theri th u ▁ gro\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁se may a ▁irukk u ▁d ▁ch ellam ▁p l z ▁d m ▁va ▁7 . 9 . in ch ▁poo lu ▁sum ma ▁eng i ▁tha vi kku ren,▁x x bo s ▁ena ku ▁unn oda ▁f ee ling ▁puri yu th u ▁ab i ▁t ry ▁pann u ▁athan ▁naan ▁un aku ▁solla ▁muti y um ▁o . k ▁un ga ▁br o ▁ku ▁mar ri ag e ▁ai du cha,▁x x bo s ▁it ha ▁lo s l iya ▁nu ▁sol it in gale,▁x x bo s ▁ne e ▁yar uda ▁ko mali ▁avan a ▁son a ▁un aku ▁ko vam ▁varu dhu ▁d n v ▁go un der ▁pan gali ▁ ah ?,▁x x bo s ▁ ama ▁e val ung a ▁pan ra ▁se tai kku ▁nam a ▁an s wer ▁pann anu ma ▁ver a ▁eth ava th u ▁vel a ▁e runth a ▁paru nga ▁pon ga\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (940 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁tak e ▁it ▁thi s ▁the vid iya ▁kan di pa ▁ind ha ▁pa ge ▁ad min ▁oru ▁mu tu al ▁pun da ▁vijay ▁f an ▁ha ▁dhan ▁eru pan,▁x x bo s ▁eng a ▁veet la ▁it ha ▁nad akum ▁a thum ▁oru ▁varu sha ma ▁tha an ▁in tha ▁te ch nic ▁us e ▁pann ren ▁ser io us ly ▁it ▁w or ks,▁x x bo s ▁ind ha ▁sal lli ▁pun da , ▁du m my ▁pun dal am ▁or ama ▁iru kan um . . . ▁in ga ▁ xxunk ▁t ag ▁sa tham ▁mat um ▁tha an ▁iru kan um ▁ xxunk ▁t ag,▁x x bo s ▁ju riya ▁poo la ▁ti er ▁1 ▁la ▁ um bur an ▁tha ▁kull a ▁pun dai ▁o ol u ▁ ook uth u ▁pa aru,▁x x bo s ▁kull ans ▁ lam ▁u mba ▁theri la ▁lo osu ▁ku thi ▁ma ari ▁u mba ▁ven d iyath a ▁saman tha ▁pun da il aye ▁illa ▁athan ▁kull an\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(8000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6d96bcbd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the pretrained language model on tamil wikipedia\n",
    "learn.load('../../dataset_preparation/models/best_model', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.714156</td>\n",
       "      <td>5.276985</td>\n",
       "      <td>0.151290</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.178426</td>\n",
       "      <td>4.931022</td>\n",
       "      <td>0.197321</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.870660</td>\n",
       "      <td>4.528532</td>\n",
       "      <td>0.247321</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.605754</td>\n",
       "      <td>4.343621</td>\n",
       "      <td>0.269048</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.408315</td>\n",
       "      <td>4.273314</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.294514</td>\n",
       "      <td>4.263070</td>\n",
       "      <td>0.277207</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en payar ▁pol ▁dayaaricapadu anu . ing hu ▁ro mba ▁veli ana'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('en payar',n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=taen_vocab, bs=16, label_cols=label_cols, text_cols=text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁o os uku ▁on num ▁pan la ▁illa . . . ▁sambal am ▁ki mbal am ▁vang arin gal a . . . na atu ka ga ▁on num ▁ne eng a ▁tho o ki ▁ni ppatu la ▁illa ▁ xxrep ▁4 ▁ . ▁ne nga ▁ar my ▁off ic ers ▁vid a ▁na atuku ▁it hu ▁pan ri ngal a ▁ xxrep ▁4 ▁ .</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁tamil ▁pon nu ▁nu ▁tho ki ▁va chu ▁a adu ni ka ▁ xxrep ▁4 ▁ . ▁iv al ▁on na ▁no ▁fa ke ▁ xxrep ▁8 ▁ . ▁ bb ▁ho me ▁l ▁ull a ▁a angal ▁all or um ▁good . . . pen n kal ▁tha an ▁the ava ▁illa ma ▁ , , c re at ▁pann uth u ka ▁ xxrep</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁iv un galukum ▁sam e ▁than dan ai ▁kudu kan um ▁a thum ▁nadu ▁ro ad ▁la iv val a vu ▁na al ▁vel a ▁pa kka ma ▁kaal ▁mel a ▁kaal ▁potu ▁sum ma ▁irundhu ▁sambal am ▁va angi tu , ▁cor on a ▁la ▁vel a ▁pa kka ▁sonna ▁an iya ayam a ▁ip di ▁kolai ▁panni tu ▁adh uku ▁sa ppa ▁sa aku</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁na ▁7 ' th ▁padi kum ▁pot hu ▁3 s ir ▁vant hang a ▁avan ga ▁nam e ▁pan di ▁ , ven kat , sar avan an ▁ ah th ula ▁venkat ▁sir ▁son nga ▁na ▁ th ri sha ▁ki t ta ▁pe asu re ▁nu ▁sol lli ▁ yen ni um ▁pe as a ▁vach anga ▁a pro ▁na ▁ph one ▁pe asu</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁ne e ▁on nu ▁pann u ▁ xxrep ▁4 ▁ . ▁vijay ▁poo lu ▁ ah ▁o om bur ath a ▁niru th ittu ▁app uku tt y ▁ oda ▁poo lu ▁ ah ▁o o mba ▁sta pan nu . . . y enna ▁avan ▁dhan a ▁periya ▁a ctor ▁un ga ▁aj ith ▁ ah ▁vid a . . . ▁awar d ▁iru k</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3200 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁avar u ▁ro mba ▁var shan ▁munn adi ▁e h ▁re ti re ▁aa y itar u ▁nu ▁ne nai chen ▁ xxrep ▁4 ▁ . ▁for m ▁la ▁irukk a ▁app o ve ▁aa ganum ▁sol l itu ▁iru par u ▁ xxunk ▁t ag,▁x x bo s ▁un go tha ▁yar u ▁un aku ▁theri um ▁un go ppan ▁mun ji ▁pat hu ▁eri ku ra ▁u h ▁da ▁the vid iya ▁pa iya le,▁x x bo s ▁at hu ▁tha an ▁avan ▁than n oda ▁in s ta gram ▁id ▁la ye ▁po du ▁iru kan e ▁vijay ▁do u ble ▁bod y ▁endu ▁un aku ▁it ha ▁vid a ▁ke val ama ▁ena ▁ven um ▁aa ▁tan e ▁ne nga ▁parthu ▁ra,▁x x bo s ▁ne e ▁on nu ▁pann u ▁ xxrep ▁4 ▁ . ▁vijay ▁poo lu ▁ ah ▁o om bur ath a ▁niru th ittu ▁app uku tt y ▁ oda ▁poo lu ▁ ah ▁o o mba ▁sta pan nu . . . y enna ▁avan ▁dhan a ▁periya ▁a ctor ▁un ga ▁aj ith ▁ ah ▁vid a . . . ▁awar d ▁iru k ur avan ▁poo lu ▁ ah ▁dhan ▁ ish tam ▁ ah ▁o o mbu va ▁ne e ▁ xxrep ▁4 ▁ . ▁po ▁ national ▁awar d ▁dhan ▁periya ▁awar d ▁ xxrep ▁4 ▁ . ▁po i ▁app u ▁kutt y ▁ ah ▁o o mbu,▁x x bo s ▁ha ter ▁of ▁aj ith ▁nu ▁ha ter ▁of ▁aj ith ▁tha ▁da ▁po du vai nga ▁en ▁chi p su ▁e po ▁viv e gam ▁un der rat ed ▁mo vi e ▁son ing lo ▁a po va e ▁un ga ▁moola i ▁pun dai ▁ pathi ▁theri th u ▁ gro\n",
       "y: CategoryList\n",
       "NOT,OFF,NOT,OFF,OFF\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁se may a ▁irukk u ▁d ▁ch ellam ▁p l z ▁d m ▁va ▁7 . 9 . in ch ▁poo lu ▁sum ma ▁eng i ▁tha vi kku ren,▁x x bo s ▁ena ku ▁unn oda ▁f ee ling ▁puri yu th u ▁ab i ▁t ry ▁pann u ▁athan ▁naan ▁un aku ▁solla ▁muti y um ▁o . k ▁un ga ▁br o ▁ku ▁mar ri ag e ▁ai du cha,▁x x bo s ▁it ha ▁lo s l iya ▁nu ▁sol it in gale,▁x x bo s ▁ne e ▁yar uda ▁ko mali ▁avan a ▁son a ▁un aku ▁ko vam ▁varu dhu ▁d n v ▁go un der ▁pan gali ▁ ah ?,▁x x bo s ▁ ama ▁e val ung a ▁pan ra ▁se tai kku ▁nam a ▁an s wer ▁pann anu ma ▁ver a ▁eth ava th u ▁vel a ▁e runth a ▁paru nga ▁pon ga\n",
       "y: CategoryList\n",
       "OFF,NOT,NOT,OFF,NOT\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (940 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁tak e ▁it ▁thi s ▁the vid iya ▁kan di pa ▁ind ha ▁pa ge ▁ad min ▁oru ▁mu tu al ▁pun da ▁vijay ▁f an ▁ha ▁dhan ▁eru pan,▁x x bo s ▁eng a ▁veet la ▁it ha ▁nad akum ▁a thum ▁oru ▁varu sha ma ▁tha an ▁in tha ▁te ch nic ▁us e ▁pann ren ▁ser io us ly ▁it ▁w or ks,▁x x bo s ▁ind ha ▁sal lli ▁pun da , ▁du m my ▁pun dal am ▁or ama ▁iru kan um . . . ▁in ga ▁ xxunk ▁t ag ▁sa tham ▁mat um ▁tha an ▁iru kan um ▁ xxunk ▁t ag,▁x x bo s ▁ju riya ▁poo la ▁ti er ▁1 ▁la ▁ um bur an ▁tha ▁kull a ▁pun dai ▁o ol u ▁ ook uth u ▁pa aru,▁x x bo s ▁kull ans ▁ lam ▁u mba ▁theri la ▁lo osu ▁ku thi ▁ma ari ▁u mba ▁ven d iyath a ▁saman tha ▁pun da il aye ▁illa ▁athan ▁kull an\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.12)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6d96bcbd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3200 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁avar u ▁ro mba ▁var shan ▁munn adi ▁e h ▁re ti re ▁aa y itar u ▁nu ▁ne nai chen ▁ xxrep ▁4 ▁ . ▁for m ▁la ▁irukk a ▁app o ve ▁aa ganum ▁sol l itu ▁iru par u ▁ xxunk ▁t ag,▁x x bo s ▁un go tha ▁yar u ▁un aku ▁theri um ▁un go ppan ▁mun ji ▁pat hu ▁eri ku ra ▁u h ▁da ▁the vid iya ▁pa iya le,▁x x bo s ▁at hu ▁tha an ▁avan ▁than n oda ▁in s ta gram ▁id ▁la ye ▁po du ▁iru kan e ▁vijay ▁do u ble ▁bod y ▁endu ▁un aku ▁it ha ▁vid a ▁ke val ama ▁ena ▁ven um ▁aa ▁tan e ▁ne nga ▁parthu ▁ra,▁x x bo s ▁ne e ▁on nu ▁pann u ▁ xxrep ▁4 ▁ . ▁vijay ▁poo lu ▁ ah ▁o om bur ath a ▁niru th ittu ▁app uku tt y ▁ oda ▁poo lu ▁ ah ▁o o mba ▁sta pan nu . . . y enna ▁avan ▁dhan a ▁periya ▁a ctor ▁un ga ▁aj ith ▁ ah ▁vid a . . . ▁awar d ▁iru k ur avan ▁poo lu ▁ ah ▁dhan ▁ ish tam ▁ ah ▁o o mbu va ▁ne e ▁ xxrep ▁4 ▁ . ▁po ▁ national ▁awar d ▁dhan ▁periya ▁awar d ▁ xxrep ▁4 ▁ . ▁po i ▁app u ▁kutt y ▁ ah ▁o o mbu,▁x x bo s ▁ha ter ▁of ▁aj ith ▁nu ▁ha ter ▁of ▁aj ith ▁tha ▁da ▁po du vai nga ▁en ▁chi p su ▁e po ▁viv e gam ▁un der rat ed ▁mo vi e ▁son ing lo ▁a po va e ▁un ga ▁moola i ▁pun dai ▁ pathi ▁theri th u ▁ gro\n",
       "y: CategoryList\n",
       "NOT,OFF,NOT,OFF,OFF\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁se may a ▁irukk u ▁d ▁ch ellam ▁p l z ▁d m ▁va ▁7 . 9 . in ch ▁poo lu ▁sum ma ▁eng i ▁tha vi kku ren,▁x x bo s ▁ena ku ▁unn oda ▁f ee ling ▁puri yu th u ▁ab i ▁t ry ▁pann u ▁athan ▁naan ▁un aku ▁solla ▁muti y um ▁o . k ▁un ga ▁br o ▁ku ▁mar ri ag e ▁ai du cha,▁x x bo s ▁it ha ▁lo s l iya ▁nu ▁sol it in gale,▁x x bo s ▁ne e ▁yar uda ▁ko mali ▁avan a ▁son a ▁un aku ▁ko vam ▁varu dhu ▁d n v ▁go un der ▁pan gali ▁ ah ?,▁x x bo s ▁ ama ▁e val ung a ▁pan ra ▁se tai kku ▁nam a ▁an s wer ▁pann anu ma ▁ver a ▁eth ava th u ▁vel a ▁e runth a ▁paru nga ▁pon ga\n",
       "y: CategoryList\n",
       "OFF,NOT,NOT,OFF,NOT\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (940 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁tak e ▁it ▁thi s ▁the vid iya ▁kan di pa ▁ind ha ▁pa ge ▁ad min ▁oru ▁mu tu al ▁pun da ▁vijay ▁f an ▁ha ▁dhan ▁eru pan,▁x x bo s ▁eng a ▁veet la ▁it ha ▁nad akum ▁a thum ▁oru ▁varu sha ma ▁tha an ▁in tha ▁te ch nic ▁us e ▁pann ren ▁ser io us ly ▁it ▁w or ks,▁x x bo s ▁ind ha ▁sal lli ▁pun da , ▁du m my ▁pun dal am ▁or ama ▁iru kan um . . . ▁in ga ▁ xxunk ▁t ag ▁sa tham ▁mat um ▁tha an ▁iru kan um ▁ xxunk ▁t ag,▁x x bo s ▁ju riya ▁poo la ▁ti er ▁1 ▁la ▁ um bur an ▁tha ▁kull a ▁pun dai ▁o ol u ▁ ook uth u ▁pa aru,▁x x bo s ▁kull ans ▁ lam ▁u mba ▁theri la ▁lo osu ▁ku thi ▁ma ari ▁u mba ▁ven d iyath a ▁saman tha ▁pun da il aye ▁illa ▁athan ▁kull an\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.12)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6d96bcbd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.12)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.12)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MatthewsCorreff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mcc, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.560550</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.631044</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first-full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.460979</td>\n",
       "      <td>0.368740</td>\n",
       "      <td>0.681285</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.365061</td>\n",
       "      <td>0.330873</td>\n",
       "      <td>0.747256</td>\n",
       "      <td>0.873750</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.291775</td>\n",
       "      <td>0.330849</td>\n",
       "      <td>0.724713</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.216459</td>\n",
       "      <td>0.407518</td>\n",
       "      <td>0.700695</td>\n",
       "      <td>0.846250</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127917</td>\n",
       "      <td>0.371191</td>\n",
       "      <td>0.724657</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.112401</td>\n",
       "      <td>0.379323</td>\n",
       "      <td>0.724656</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.8737499713897705.\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='final')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3200 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁avar u ▁ro mba ▁var shan ▁munn adi ▁e h ▁re ti re ▁aa y itar u ▁nu ▁ne nai chen ▁ xxrep ▁4 ▁ . ▁for m ▁la ▁irukk a ▁app o ve ▁aa ganum ▁sol l itu ▁iru par u ▁ xxunk ▁t ag,▁x x bo s ▁un go tha ▁yar u ▁un aku ▁theri um ▁un go ppan ▁mun ji ▁pat hu ▁eri ku ra ▁u h ▁da ▁the vid iya ▁pa iya le,▁x x bo s ▁at hu ▁tha an ▁avan ▁than n oda ▁in s ta gram ▁id ▁la ye ▁po du ▁iru kan e ▁vijay ▁do u ble ▁bod y ▁endu ▁un aku ▁it ha ▁vid a ▁ke val ama ▁ena ▁ven um ▁aa ▁tan e ▁ne nga ▁parthu ▁ra,▁x x bo s ▁ne e ▁on nu ▁pann u ▁ xxrep ▁4 ▁ . ▁vijay ▁poo lu ▁ ah ▁o om bur ath a ▁niru th ittu ▁app uku tt y ▁ oda ▁poo lu ▁ ah ▁o o mba ▁sta pan nu . . . y enna ▁avan ▁dhan a ▁periya ▁a ctor ▁un ga ▁aj ith ▁ ah ▁vid a . . . ▁awar d ▁iru k ur avan ▁poo lu ▁ ah ▁dhan ▁ ish tam ▁ ah ▁o o mbu va ▁ne e ▁ xxrep ▁4 ▁ . ▁po ▁ national ▁awar d ▁dhan ▁periya ▁awar d ▁ xxrep ▁4 ▁ . ▁po i ▁app u ▁kutt y ▁ ah ▁o o mbu,▁x x bo s ▁ha ter ▁of ▁aj ith ▁nu ▁ha ter ▁of ▁aj ith ▁tha ▁da ▁po du vai nga ▁en ▁chi p su ▁e po ▁viv e gam ▁un der rat ed ▁mo vi e ▁son ing lo ▁a po va e ▁un ga ▁moola i ▁pun dai ▁ pathi ▁theri th u ▁ gro\n",
       "y: CategoryList\n",
       "NOT,OFF,NOT,OFF,OFF\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁se may a ▁irukk u ▁d ▁ch ellam ▁p l z ▁d m ▁va ▁7 . 9 . in ch ▁poo lu ▁sum ma ▁eng i ▁tha vi kku ren,▁x x bo s ▁ena ku ▁unn oda ▁f ee ling ▁puri yu th u ▁ab i ▁t ry ▁pann u ▁athan ▁naan ▁un aku ▁solla ▁muti y um ▁o . k ▁un ga ▁br o ▁ku ▁mar ri ag e ▁ai du cha,▁x x bo s ▁it ha ▁lo s l iya ▁nu ▁sol it in gale,▁x x bo s ▁ne e ▁yar uda ▁ko mali ▁avan a ▁son a ▁un aku ▁ko vam ▁varu dhu ▁d n v ▁go un der ▁pan gali ▁ ah ?,▁x x bo s ▁ ama ▁e val ung a ▁pan ra ▁se tai kku ▁nam a ▁an s wer ▁pann anu ma ▁ver a ▁eth ava th u ▁vel a ▁e runth a ▁paru nga ▁pon ga\n",
       "y: CategoryList\n",
       "OFF,NOT,NOT,OFF,NOT\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (940 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁tak e ▁it ▁thi s ▁the vid iya ▁kan di pa ▁ind ha ▁pa ge ▁ad min ▁oru ▁mu tu al ▁pun da ▁vijay ▁f an ▁ha ▁dhan ▁eru pan,▁x x bo s ▁eng a ▁veet la ▁it ha ▁nad akum ▁a thum ▁oru ▁varu sha ma ▁tha an ▁in tha ▁te ch nic ▁us e ▁pann ren ▁ser io us ly ▁it ▁w or ks,▁x x bo s ▁ind ha ▁sal lli ▁pun da , ▁du m my ▁pun dal am ▁or ama ▁iru kan um . . . ▁in ga ▁ xxunk ▁t ag ▁sa tham ▁mat um ▁tha an ▁iru kan um ▁ xxunk ▁t ag,▁x x bo s ▁ju riya ▁poo la ▁ti er ▁1 ▁la ▁ um bur an ▁tha ▁kull a ▁pun dai ▁o ol u ▁ ook uth u ▁pa aru,▁x x bo s ▁kull ans ▁ lam ▁u mba ▁theri la ▁lo osu ▁ku thi ▁ma ari ▁u mba ▁ven d iyath a ▁saman tha ▁pun da il aye ▁illa ▁athan ▁kull an\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.24)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f6d96bcbd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (3200 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁avar u ▁ro mba ▁var shan ▁munn adi ▁e h ▁re ti re ▁aa y itar u ▁nu ▁ne nai chen ▁ xxrep ▁4 ▁ . ▁for m ▁la ▁irukk a ▁app o ve ▁aa ganum ▁sol l itu ▁iru par u ▁ xxunk ▁t ag,▁x x bo s ▁un go tha ▁yar u ▁un aku ▁theri um ▁un go ppan ▁mun ji ▁pat hu ▁eri ku ra ▁u h ▁da ▁the vid iya ▁pa iya le,▁x x bo s ▁at hu ▁tha an ▁avan ▁than n oda ▁in s ta gram ▁id ▁la ye ▁po du ▁iru kan e ▁vijay ▁do u ble ▁bod y ▁endu ▁un aku ▁it ha ▁vid a ▁ke val ama ▁ena ▁ven um ▁aa ▁tan e ▁ne nga ▁parthu ▁ra,▁x x bo s ▁ne e ▁on nu ▁pann u ▁ xxrep ▁4 ▁ . ▁vijay ▁poo lu ▁ ah ▁o om bur ath a ▁niru th ittu ▁app uku tt y ▁ oda ▁poo lu ▁ ah ▁o o mba ▁sta pan nu . . . y enna ▁avan ▁dhan a ▁periya ▁a ctor ▁un ga ▁aj ith ▁ ah ▁vid a . . . ▁awar d ▁iru k ur avan ▁poo lu ▁ ah ▁dhan ▁ ish tam ▁ ah ▁o o mbu va ▁ne e ▁ xxrep ▁4 ▁ . ▁po ▁ national ▁awar d ▁dhan ▁periya ▁awar d ▁ xxrep ▁4 ▁ . ▁po i ▁app u ▁kutt y ▁ ah ▁o o mbu,▁x x bo s ▁ha ter ▁of ▁aj ith ▁nu ▁ha ter ▁of ▁aj ith ▁tha ▁da ▁po du vai nga ▁en ▁chi p su ▁e po ▁viv e gam ▁un der rat ed ▁mo vi e ▁son ing lo ▁a po va e ▁un ga ▁moola i ▁pun dai ▁ pathi ▁theri th u ▁ gro\n",
       "y: CategoryList\n",
       "NOT,OFF,NOT,OFF,OFF\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (800 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁se may a ▁irukk u ▁d ▁ch ellam ▁p l z ▁d m ▁va ▁7 . 9 . in ch ▁poo lu ▁sum ma ▁eng i ▁tha vi kku ren,▁x x bo s ▁ena ku ▁unn oda ▁f ee ling ▁puri yu th u ▁ab i ▁t ry ▁pann u ▁athan ▁naan ▁un aku ▁solla ▁muti y um ▁o . k ▁un ga ▁br o ▁ku ▁mar ri ag e ▁ai du cha,▁x x bo s ▁it ha ▁lo s l iya ▁nu ▁sol it in gale,▁x x bo s ▁ne e ▁yar uda ▁ko mali ▁avan a ▁son a ▁un aku ▁ko vam ▁varu dhu ▁d n v ▁go un der ▁pan gali ▁ ah ?,▁x x bo s ▁ ama ▁e val ung a ▁pan ra ▁se tai kku ▁nam a ▁an s wer ▁pann anu ma ▁ver a ▁eth ava th u ▁vel a ▁e runth a ▁paru nga ▁pon ga\n",
       "y: CategoryList\n",
       "OFF,NOT,NOT,OFF,NOT\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (940 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁tak e ▁it ▁thi s ▁the vid iya ▁kan di pa ▁ind ha ▁pa ge ▁ad min ▁oru ▁mu tu al ▁pun da ▁vijay ▁f an ▁ha ▁dhan ▁eru pan,▁x x bo s ▁eng a ▁veet la ▁it ha ▁nad akum ▁a thum ▁oru ▁varu sha ma ▁tha an ▁in tha ▁te ch nic ▁us e ▁pann ren ▁ser io us ly ▁it ▁w or ks,▁x x bo s ▁ind ha ▁sal lli ▁pun da , ▁du m my ▁pun dal am ▁or ama ▁iru kan um . . . ▁in ga ▁ xxunk ▁t ag ▁sa tham ▁mat um ▁tha an ▁iru kan um ▁ xxunk ▁t ag,▁x x bo s ▁ju riya ▁poo la ▁ti er ▁1 ▁la ▁ um bur an ▁tha ▁kull a ▁pun dai ▁o ol u ▁ ook uth u ▁pa aru,▁x x bo s ▁kull ans ▁ lam ▁u mba ▁theri la ▁lo osu ▁ku thi ▁ma ari ▁u mba ▁ven d iyath a ▁saman tha ▁pun da il aye ▁illa ▁athan ▁kull an\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.24)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7f6d96bcbd08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.24)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.24)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>OFF</th>\n",
       "      <th>NOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER Semaya irukku D chellam plz dm va 7.9.in...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.247348</td>\n",
       "      <td>0.752652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER Enaku unnoda Feeling puriyuthu abi Try p...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.304944</td>\n",
       "      <td>0.695055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itha losliya nu solitingale</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.540392</td>\n",
       "      <td>0.459608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER nee yaruda komali avana sona unaku kovam...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.82265</td>\n",
       "      <td>0.17735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ama evalunga panra setaikku nama answer pannan...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.17148</td>\n",
       "      <td>0.82852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query actual_label  \\\n",
       "0  @USER Semaya irukku D chellam plz dm va 7.9.in...          OFF   \n",
       "1  @USER Enaku unnoda Feeling puriyuthu abi Try p...          NOT   \n",
       "2                        itha losliya nu solitingale          NOT   \n",
       "3  @USER nee yaruda komali avana sona unaku kovam...          OFF   \n",
       "4  ama evalunga panra setaikku nama answer pannan...          NOT   \n",
       "\n",
       "  predicted_label       OFF       NOT  \n",
       "0             NOT  0.247348  0.752652  \n",
       "1             NOT  0.304944  0.695055  \n",
       "2             OFF  0.540392  0.459608  \n",
       "3             OFF   0.82265   0.17735  \n",
       "4             NOT   0.17148   0.82852  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_valid.copy()\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'query': list(df_test[1]), 'actual_label': list(df_test[2]), 'predicted_label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train[2]))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Valid, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86875"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7389336833200368"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692403486924035"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_result['actual_label'], df_result['predicted_label'], labels=['NOT ', 'OFF'], pos_label='OFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>NOT</th>\n",
       "      <th>OFF</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dai pavam Pannita kandipa unnaku punishment ka...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.451207</td>\n",
       "      <td>0.548793</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>@USER Appa, antha SivaKarthikeyan vanthu unaku...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.399875</td>\n",
       "      <td>0.600125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>@USER Unaku erinjinu iruka naala dhana ketunu ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.660396</td>\n",
       "      <td>0.339604</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>@USER Indha trackers ellam ippo vandhavanga , ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.434618</td>\n",
       "      <td>0.565382</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>intha mari video eduthu pullaigala koothadi aa...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.354108</td>\n",
       "      <td>0.645892</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>@USER Enga Yarum Dhanush ahh Pathi Romba Muttu...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.593903</td>\n",
       "      <td>0.406097</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Kithan vaai da unaku...Vadai suttu suttaey val...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.627966</td>\n",
       "      <td>0.372034</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>@USER Pappan kasu kudutha ena vena seivan Ithu...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.831375</td>\n",
       "      <td>0.168625</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>RT @USER : Idhula edhachum thappa sollirukaen ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.765768</td>\n",
       "      <td>0.234232</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>ipalam ivala pathalea irritate aagudhu</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.182997</td>\n",
       "      <td>0.817003</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>@USER Yaenda loosu payalae endha naata vida ba...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.385911</td>\n",
       "      <td>0.614089</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>@USER Vekkama illanga ungaluku. Sethathu Unga ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.238478</td>\n",
       "      <td>0.761522</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 query actual_label  \\\n",
       "7    Dai pavam Pannita kandipa unnaku punishment ka...          NOT   \n",
       "220  @USER Appa, antha SivaKarthikeyan vanthu unaku...          NOT   \n",
       "222  @USER Unaku erinjinu iruka naala dhana ketunu ...          OFF   \n",
       "313  @USER Indha trackers ellam ippo vandhavanga , ...          NOT   \n",
       "316  intha mari video eduthu pullaigala koothadi aa...          NOT   \n",
       "369  @USER Enga Yarum Dhanush ahh Pathi Romba Muttu...          OFF   \n",
       "392  Kithan vaai da unaku...Vadai suttu suttaey val...          OFF   \n",
       "503  @USER Pappan kasu kudutha ena vena seivan Ithu...          OFF   \n",
       "683  RT @USER : Idhula edhachum thappa sollirukaen ...          OFF   \n",
       "697             ipalam ivala pathalea irritate aagudhu          NOT   \n",
       "744  @USER Yaenda loosu payalae endha naata vida ba...          NOT   \n",
       "788  @USER Vekkama illanga ungaluku. Sethathu Unga ...          NOT   \n",
       "\n",
       "    predicted_label       NOT       OFF  status  \n",
       "7               OFF  0.451207  0.548793   False  \n",
       "220             OFF  0.399875  0.600125   False  \n",
       "222             NOT  0.660396  0.339604   False  \n",
       "313             OFF  0.434618  0.565382   False  \n",
       "316             OFF  0.354108  0.645892   False  \n",
       "369             NOT  0.593903  0.406097   False  \n",
       "392             NOT  0.627966  0.372034   False  \n",
       "503             NOT  0.831375  0.168625   False  \n",
       "683             NOT  0.765768  0.234232   False  \n",
       "697             OFF  0.182997  0.817003   False  \n",
       "744             OFF  0.385911  0.614089   False  \n",
       "788             OFF  0.238478  0.761522   False  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['status'] = df_result['actual_label']==df_result['predicted_label']\n",
    "df_result[df_result['status']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@USER Naam tamilarai pesurathum tamilargalai onu illa. Apram nan yaaru kaasula padikka vanthen nu unaku epdi raja theriyum Velakku ethum pudichaya. And en sex life ah pathi pesa thaguthi Because you don't have any life, bastard.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.iloc[13]['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category NOT, tensor(0), tensor([0.9041, 0.0959]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"Naam tamilarai pesurathum tamilargalai onu illa. Apram nan yaaru kaasula padikka vanthen nu unaku epdi raja theriyum Velakku ethum pudichaya. And en sex life ah pathi pesa thaguthi Because you don't have any life, bastard.\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>NOT</th>\n",
       "      <th>OFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA_TW15946</td>\n",
       "      <td>Take it this thevidiya Kandipa indha page admi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.0140025</td>\n",
       "      <td>0.985997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA_TW10175</td>\n",
       "      <td>enga veetla itha nadakum Athum oru varushama t...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.971736</td>\n",
       "      <td>0.0282636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA_TW15947</td>\n",
       "      <td>Indha Sallli Punda, Dummy Pundalam Orama Iruka...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.00695224</td>\n",
       "      <td>0.993048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA_TW15174</td>\n",
       "      <td>Juriya poola tier 1 la umburan tha kulla punda...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.00167357</td>\n",
       "      <td>0.998326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA_TW15182</td>\n",
       "      <td>Kullans lam umba therila Loosu kuthi maari umb...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>0.00564466</td>\n",
       "      <td>0.994355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text label  \\\n",
       "0  TA_TW15946  Take it this thevidiya Kandipa indha page admi...   OFF   \n",
       "1  TA_TW10175  enga veetla itha nadakum Athum oru varushama t...   NOT   \n",
       "2  TA_TW15947  Indha Sallli Punda, Dummy Pundalam Orama Iruka...   OFF   \n",
       "3  TA_TW15174  Juriya poola tier 1 la umburan tha kulla punda...   OFF   \n",
       "4  TA_TW15182  Kullans lam umba therila Loosu kuthi maari umb...   OFF   \n",
       "\n",
       "          NOT        OFF  \n",
       "0   0.0140025   0.985997  \n",
       "1    0.971736  0.0282636  \n",
       "2  0.00695224   0.993048  \n",
       "3  0.00167357   0.998326  \n",
       "4  0.00564466   0.994355  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../hasoc_task_2/Tamil_hasoc_tanglish_test_without_labels.tsv', sep='\\t', header=None)\n",
    "df_test.dropna(inplace=True)\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'id': list(df_test[0]), 'text': list(df_test[1]), 'label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train[2]))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    row['label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477, 5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result['label']=='NOT'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('test_res2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category OFF, tensor(1), tensor([0.4558, 0.5442]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Dawali-ah irukara Kanagavel pathi mulusa therinjika indha padam paarunga. tonight at 7 PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in",
   "language": "python",
   "name": "in"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
