{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.0.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)  \n",
    "    torch.manual_seed(seed_value)  \n",
    "    random.seed(seed_value)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  \n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/ubuntu/gaurav/in/fire/code-mixed-enta/classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trailer late ah parthavanga like podunga</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Move pathutu vanthu trailer pakurvnga yaru</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puthupetai dhanush  ah yarellam pathinga</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dhanush oda character ,puthu sa erukay , mass ta</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vera level ippa pesungada mokka nu thalaivaaaaaa</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   category\n",
       "0           Trailer late ah parthavanga like podunga  Positive \n",
       "1         Move pathutu vanthu trailer pakurvnga yaru  Positive \n",
       "2           Puthupetai dhanush  ah yarellam pathinga  Positive \n",
       "3   Dhanush oda character ,puthu sa erukay , mass ta  Positive \n",
       "4   vera level ippa pesungada mokka nu thalaivaaaaaa  Positive "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(path/'../dc_fire/tamil_train.tsv', sep='\\t')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Mixed_feelings ': 1283,\n",
       "         'Negative ': 1448,\n",
       "         'Positive ': 7627,\n",
       "         'not-Tamil ': 368,\n",
       "         'unknown_state ': 609})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # In an attempt to solve class-imbalance\n",
    "# df_mf = df_train[df_train['category']=='Mixed_feelings ']\n",
    "# df_neg = df_train[df_train['category']=='Negative ']\n",
    "# df_nott = df_train[df_train['category']=='not-Tamil ']\n",
    "# df_us = df_train[df_train['category']=='unknown_state ']\n",
    "# print(df_mf.shape, df_neg.shape, df_nott.shape, df_us.shape)\n",
    "# df_train = pd.concat([df_train, df_mf, df_neg, df_nott, df_us, df_mf, df_neg, df_nott, df_us])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Mixed_feelings ': 1283,\n",
       "         'Negative ': 1448,\n",
       "         'Positive ': 7627,\n",
       "         'not-Tamil ': 368,\n",
       "         'unknown_state ': 609})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily likes &amp; views pakka vanthavaga ellaruku...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25 k dislikes ethuku da intha trailerku poi a...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Lyca unna nenacha pavama iruku ya</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It looks like Hindi movie amitab bachan</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thalaivarukku nejamavey vayasaagiduchu... siv...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         category\n",
       "0   Daily likes & views pakka vanthavaga ellaruku...        Positive \n",
       "1   25 k dislikes ethuku da intha trailerku poi a...        Negative \n",
       "2                 #Lyca unna nenacha pavama iruku ya  Mixed_feelings \n",
       "3            It looks like Hindi movie amitab bachan        Positive \n",
       "4   Thalaivarukku nejamavey vayasaagiduchu... siv...        Positive "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv(path/'../dc_fire/tamil_dev.tsv', sep='\\t')\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In an attempt to create two stage classifier\n",
    "# orig_class = list(df_valid['category'])\n",
    "# orig_class = [cls if cls == 'Positive ' else 'Other' for cls in orig_class]\n",
    "# df_valid['category'] = orig_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Mixed_feelings ': 141,\n",
       "         'Negative ': 165,\n",
       "         'Positive ': 857,\n",
       "         'not-Tamil ': 29,\n",
       "         'unknown_state ': 68})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_valid['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ta_sent_1</td>\n",
       "      <td>Yarayellam FDFS ppga ippove ready agitinga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ta_sent_2</td>\n",
       "      <td>Ennada viswasam mersal sarkar madhri time la l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ta_sent_3</td>\n",
       "      <td>yuvan vera level ya .... valuable script. SK i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ta_sent_4</td>\n",
       "      <td>70 vayasulayum thanoda rasigargala sandhosapad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ta_sent_5</td>\n",
       "      <td>all the best anna...Telugu makkal selvan fans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text\n",
       "0  ta_sent_1         Yarayellam FDFS ppga ippove ready agitinga\n",
       "1  ta_sent_2  Ennada viswasam mersal sarkar madhri time la l...\n",
       "2  ta_sent_3  yuvan vera level ya .... valuable script. SK i...\n",
       "3  ta_sent_4  70 vayasulayum thanoda rasigargala sandhosapad...\n",
       "4  ta_sent_5      all the best anna...Telugu makkal selvan fans"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../dc_fire/tamil_test.tsv', sep='\\t')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11335, 2), (1260, 2), (3149, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12595, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_train, df_valid])\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['category']\n",
    "text_cols = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_all_caps(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = replace_all_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def handle_upper_case_first_letter(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = deal_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def lower_case_everything(t: str) -> str:\n",
    "    return t.lower().replace('@user', '').replace('#tag ', '').replace('rt ', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMixedTamilTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(path/\"../tokenizer/taen_spm.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/taen_spm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxpad',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '.',\n",
       " ',',\n",
       " '▁',\n",
       " 's',\n",
       " 'a',\n",
       " '=\"',\n",
       " 'in',\n",
       " 'doc',\n",
       " 't',\n",
       " 'il',\n",
       " 'i']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8,000 is the vocab size that we chose in sentencepiece\n",
    "taen_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lang='taen', tok_func=CodeMixedTamilTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_rules.append(lower_case_everything)\n",
    "tokenizer.pre_rules.append(handle_all_caps)\n",
    "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep'],\n",
       " [<function fastai.text.transform.fix_html>,\n",
       "  <function fastai.text.transform.replace_rep>,\n",
       "  <function fastai.text.transform.replace_wrep>,\n",
       "  <function fastai.text.transform.spec_add_spaces>,\n",
       "  <function fastai.text.transform.rm_useless_spaces>,\n",
       "  <function __main__.lower_case_everything>,\n",
       "  <function __main__.handle_all_caps>,\n",
       "  <function __main__.handle_upper_case_first_letter>],\n",
       " [<function fastai.text.transform.replace_all_caps>,\n",
       "  <function fastai.text.transform.deal_caps>])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁tell▁me▁about▁tour▁self,▁mujhe▁jaanna▁hai'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.process_all(['Tell me about TOUR self, mujhe jaanna hai'])\n",
    "''.join(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=taen_vocab, label_cols=label_cols, text_cols=text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>, put hu ▁sa ▁eru kay ▁ , ▁mas s ▁ ta ▁x x bo s ▁ver a ▁le vel ▁ ippa ▁pes ung ada ▁mo kka ▁nu ▁tha lai v ▁ xxrep ▁6 ▁a ▁x x bo s ▁tha la ▁mas s ▁ . ▁u 1 ▁b g m . ▁ver a ▁le vel ▁x x bo s ▁ivar a ▁ path ta ▁de ath ▁ vadi ▁madi ri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁ odi ▁po iru ▁kol a ▁kand ula ▁irukk a en ▁padam ▁pa ak ama ▁vid ama ta en ▁x x bo s ▁el am ▁ gir ls ▁ um ▁tra il er ▁ ah ▁pat ha ▁ma ari ▁mo vi e ▁ya ▁kan di pa a ▁paru nga a ▁ xxrep ▁4 ▁ . ▁x x bo s ▁3 ena ▁da ▁300 ▁sp ar tan ▁s ▁b g m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ru ▁va kk il ▁rang a raj ▁pan de y ▁dhan a ▁avar u ▁x x bo s ▁ini ▁je n m ath h uku ▁mee than e , ▁ hydro car bon ▁ path hi ▁ne na chi ▁ko oda ▁pa ak a ▁mudiya adhu ▁cor por ates . . ▁el a ▁padam um ▁ini ▁adh a pathi ▁da an . . ▁x x bo s ▁tha la ▁se</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁ xxunk ▁chu m ma ▁a thiru th u ▁x x bo s ▁e ▁ka ▁ba wasi r ▁ban a ▁di ye ▁ho ▁x x bo s ▁are ▁yo u ▁vir gin ▁sc ene ▁iru ka ▁x x bo s ▁maran a ▁ wai ting ▁for ▁n k p ▁f d f s ▁ku ▁x x bo s ▁ivaruku ▁vay asu ▁agal a ▁vay asu ▁kor an chu kitu ▁iru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>s ▁he y , ▁dis like ▁pann a vell aam ▁ap di ye ▁ odi ▁po idu . . ▁kol a ▁ka andu la ▁iru ken . . ▁x x bo s ▁ xxunk ▁1 ▁on ▁tre nd ing ▁in ▁sri ▁ lan ka . . . ▁ne e ▁va a ▁tha la . . . ▁x x bo s ▁v j s ▁n na ▁di al o gu e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (12595 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁tra il er ▁la te ▁ ah ▁parth avan ga ▁ like ▁po du nga,▁x x bo s ▁mo ve ▁pat hu tu ▁vant hu ▁tra il er ▁pa k ur v nga ▁yar u,▁x x bo s ▁put hu pe tai ▁dhan u sh ▁ ah ▁yar ellam ▁pathin ga,▁x x bo s ▁dhan u sh ▁ oda ▁chara c ter ▁ , put hu ▁sa ▁eru kay ▁ , ▁mas s ▁ ta,▁x x bo s ▁ver a ▁le vel ▁ ippa ▁pes ung ada ▁mo kka ▁nu ▁tha lai v ▁ xxrep ▁6 ▁a\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (1260 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁da il y ▁li kes ▁ xxunk ▁vi e ws ▁pa kka ▁van th ava ga ▁ella ru kum ▁van ak kam,▁x x bo s ▁25 ▁k ▁dis like s ▁eth uku ▁da ▁in tha ▁tra il er ku ▁po i ▁ap di ▁un gal ukku ▁en tha ▁tra il er ▁tha ▁pi di kum,▁x x bo s ▁ xxunk ▁ ly ca ▁unna ▁ne na cha ▁pa vam a ▁iru ku ▁ya,▁x x bo s ▁it ▁l ook s ▁ like ▁hi ndi ▁mo vi e ▁ami ta b ▁ba chan,▁x x bo s ▁tha lai var ukku ▁ne jam ave y ▁vay as a ag idu chu . . . ▁siva ji ▁than ▁tha lai var oda ▁pe ak xxunk\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (3149 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁yar ay ellam ▁f d f s ▁p p ga ▁ip po ve ▁re ad y ▁ag iti nga,▁x x bo s ▁enna da ▁vis wa sam ▁mer sal ▁sar kar ▁madhri ▁tim e ▁la ▁li kes ▁and ▁vi e ws ▁cr e ate ▁pann alaya e,▁x x bo s ▁yu van ▁ver a ▁le vel ▁ya ▁ xxrep ▁4 ▁ . ▁valu ab le ▁sc ri p t . ▁s k ▁in ▁a ction,▁x x bo s ▁70 ▁vay asu l ay um ▁than oda ▁rasi gar gal a ▁sand ho s apadu tha ▁ip di ▁ula iku ra ru ▁ivar a ▁po i ▁ka y apadu th ur anu ngal e ▁e cha in ga ▁ula chu ▁va al an um,▁x x bo s ▁all ▁the ▁be st ▁anna . . . te lu gu ▁ma kkal ▁selva n ▁f ans\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(8000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb5427e4d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (12595 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁tra il er ▁la te ▁ ah ▁parth avan ga ▁ like ▁po du nga,▁x x bo s ▁mo ve ▁pat hu tu ▁vant hu ▁tra il er ▁pa k ur v nga ▁yar u,▁x x bo s ▁put hu pe tai ▁dhan u sh ▁ ah ▁yar ellam ▁pathin ga,▁x x bo s ▁dhan u sh ▁ oda ▁chara c ter ▁ , put hu ▁sa ▁eru kay ▁ , ▁mas s ▁ ta,▁x x bo s ▁ver a ▁le vel ▁ ippa ▁pes ung ada ▁mo kka ▁nu ▁tha lai v ▁ xxrep ▁6 ▁a\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (1260 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁da il y ▁li kes ▁ xxunk ▁vi e ws ▁pa kka ▁van th ava ga ▁ella ru kum ▁van ak kam,▁x x bo s ▁25 ▁k ▁dis like s ▁eth uku ▁da ▁in tha ▁tra il er ku ▁po i ▁ap di ▁un gal ukku ▁en tha ▁tra il er ▁tha ▁pi di kum,▁x x bo s ▁ xxunk ▁ ly ca ▁unna ▁ne na cha ▁pa vam a ▁iru ku ▁ya,▁x x bo s ▁it ▁l ook s ▁ like ▁hi ndi ▁mo vi e ▁ami ta b ▁ba chan,▁x x bo s ▁tha lai var ukku ▁ne jam ave y ▁vay as a ag idu chu . . . ▁siva ji ▁than ▁tha lai var oda ▁pe ak xxunk\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (3149 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁yar ay ellam ▁f d f s ▁p p ga ▁ip po ve ▁re ad y ▁ag iti nga,▁x x bo s ▁enna da ▁vis wa sam ▁mer sal ▁sar kar ▁madhri ▁tim e ▁la ▁li kes ▁and ▁vi e ws ▁cr e ate ▁pann alaya e,▁x x bo s ▁yu van ▁ver a ▁le vel ▁ya ▁ xxrep ▁4 ▁ . ▁valu ab le ▁sc ri p t . ▁s k ▁in ▁a ction,▁x x bo s ▁70 ▁vay asu l ay um ▁than oda ▁rasi gar gal a ▁sand ho s apadu tha ▁ip di ▁ula iku ra ru ▁ivar a ▁po i ▁ka y apadu th ur anu ngal e ▁e cha in ga ▁ula chu ▁va al an um,▁x x bo s ▁all ▁the ▁be st ▁anna . . . te lu gu ▁ma kkal ▁selva n ▁f ans\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(8000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb5427e4d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('../../dataset_preparation/models/best_model', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.602516</td>\n",
       "      <td>4.084794</td>\n",
       "      <td>0.304241</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.878182</td>\n",
       "      <td>3.585127</td>\n",
       "      <td>0.375474</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.548992</td>\n",
       "      <td>3.315666</td>\n",
       "      <td>0.413728</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.383756</td>\n",
       "      <td>3.271243</td>\n",
       "      <td>0.419280</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en payar ▁rutte ▁chan t p ▁pol ▁cinema ▁pot ta ▁da kka'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('en payar',n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=taen_vocab, bs=128, label_cols=label_cols, text_cols=text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁ver a a a ▁le v ▁ xxrep ▁6 ▁l ▁tha lai va a a ▁ xxrep ▁7 ▁ . ▁av lo o o ▁yo ung ▁ ah h h ▁ka at irkan g ▁ xxrep ▁6 ▁a ▁ xxrep ▁6 ▁ . ▁ant ha ▁s ty le ▁kor aya ave ee ▁illa a ▁ xxrep ▁5 ▁ . ▁pe ee ▁ xxrep ▁4 ▁t ▁aa</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁su per ▁star . . na a . ▁su per ▁star . . tha a a . . ▁maran a ▁wat ing ▁ xxrep ▁9 ▁ . ▁d ▁ xxrep ▁7 ▁a ▁ . . . vai nga . . da a . ▁ . mar on am . . mas s . . mar anam . . thal ai var . var an um .</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁ye van uk ava th u ▁pon ta ti ▁kol a ndha ▁kutt y ▁sent i ment ▁iru ndha ▁ap di ye ▁ odi ▁po idu . . . kol ag andu la ▁ir ken . . . koll ama ▁vid ama ten ▁ xxrep ▁4 ▁ . ▁tha lai var ▁mas s ▁ xxrep ▁4 ▁ . ▁i ▁am ▁e a ger ly ▁ wai</td>\n",
       "      <td>unknown_state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁tha lai v ▁ xxrep ▁6 ▁a ▁ne e ga a ▁e ap av um ▁mas s ▁ xxrep ▁6 ▁ . ▁se ma ▁s ty le ▁ xxrep ▁4 ▁ . ▁i am ▁ad di c ted ▁ xxrep ▁4 ▁ . ▁wat ch ing ▁aga in ▁and ▁aga in ▁ xxrep ▁6 ▁ . ▁f d f s ▁kol a a ▁mas s ▁aga</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁ini me ▁ho ll y wood ▁f li m ▁ lam ▁kidai yat hu ▁ xxunk ▁2 po in t 0 ▁koll y wood ▁math i ri ▁than ▁ xxunk shan kar shan mu gh ▁tha ram ana ▁w or k ▁ xxunk ▁tha lai va a _ un nal a mudiyath ath u _ in num _ enna _ ir uku ▁ xxunk raj ini</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (12595 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁tra il er ▁la te ▁ ah ▁parth avan ga ▁ like ▁po du nga,▁x x bo s ▁mo ve ▁pat hu tu ▁vant hu ▁tra il er ▁pa k ur v nga ▁yar u,▁x x bo s ▁put hu pe tai ▁dhan u sh ▁ ah ▁yar ellam ▁pathin ga,▁x x bo s ▁dhan u sh ▁ oda ▁chara c ter ▁ , put hu ▁sa ▁eru kay ▁ , ▁mas s ▁ ta,▁x x bo s ▁ver a ▁le vel ▁ ippa ▁pes ung ada ▁mo kka ▁nu ▁tha lai v ▁ xxrep ▁6 ▁a\n",
       "y: CategoryList\n",
       "Positive ,Positive ,Positive ,Positive ,Positive \n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (1260 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁da il y ▁li kes ▁ xxunk ▁vi e ws ▁pa kka ▁van th ava ga ▁ella ru kum ▁van ak kam,▁x x bo s ▁25 ▁k ▁dis like s ▁eth uku ▁da ▁in tha ▁tra il er ku ▁po i ▁ap di ▁un gal ukku ▁en tha ▁tra il er ▁tha ▁pi di kum,▁x x bo s ▁ xxunk ▁ ly ca ▁unna ▁ne na cha ▁pa vam a ▁iru ku ▁ya,▁x x bo s ▁it ▁l ook s ▁ like ▁hi ndi ▁mo vi e ▁ami ta b ▁ba chan,▁x x bo s ▁tha lai var ukku ▁ne jam ave y ▁vay as a ag idu chu . . . ▁siva ji ▁than ▁tha lai var oda ▁pe ak xxunk\n",
       "y: CategoryList\n",
       "Positive ,Negative ,Mixed_feelings ,Positive ,Positive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (3149 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁yar ay ellam ▁f d f s ▁p p ga ▁ip po ve ▁re ad y ▁ag iti nga,▁x x bo s ▁enna da ▁vis wa sam ▁mer sal ▁sar kar ▁madhri ▁tim e ▁la ▁li kes ▁and ▁vi e ws ▁cr e ate ▁pann alaya e,▁x x bo s ▁yu van ▁ver a ▁le vel ▁ya ▁ xxrep ▁4 ▁ . ▁valu ab le ▁sc ri p t . ▁s k ▁in ▁a ction,▁x x bo s ▁70 ▁vay asu l ay um ▁than oda ▁rasi gar gal a ▁sand ho s apadu tha ▁ip di ▁ula iku ra ru ▁ivar a ▁po i ▁ka y apadu th ur anu ngal e ▁e cha in ga ▁ula chu ▁va al an um,▁x x bo s ▁all ▁the ▁be st ▁anna . . . te lu gu ▁ma kkal ▁selva n ▁f ans\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb5427e4d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (12595 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁tra il er ▁la te ▁ ah ▁parth avan ga ▁ like ▁po du nga,▁x x bo s ▁mo ve ▁pat hu tu ▁vant hu ▁tra il er ▁pa k ur v nga ▁yar u,▁x x bo s ▁put hu pe tai ▁dhan u sh ▁ ah ▁yar ellam ▁pathin ga,▁x x bo s ▁dhan u sh ▁ oda ▁chara c ter ▁ , put hu ▁sa ▁eru kay ▁ , ▁mas s ▁ ta,▁x x bo s ▁ver a ▁le vel ▁ ippa ▁pes ung ada ▁mo kka ▁nu ▁tha lai v ▁ xxrep ▁6 ▁a\n",
       "y: CategoryList\n",
       "Positive ,Positive ,Positive ,Positive ,Positive \n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (1260 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁da il y ▁li kes ▁ xxunk ▁vi e ws ▁pa kka ▁van th ava ga ▁ella ru kum ▁van ak kam,▁x x bo s ▁25 ▁k ▁dis like s ▁eth uku ▁da ▁in tha ▁tra il er ku ▁po i ▁ap di ▁un gal ukku ▁en tha ▁tra il er ▁tha ▁pi di kum,▁x x bo s ▁ xxunk ▁ ly ca ▁unna ▁ne na cha ▁pa vam a ▁iru ku ▁ya,▁x x bo s ▁it ▁l ook s ▁ like ▁hi ndi ▁mo vi e ▁ami ta b ▁ba chan,▁x x bo s ▁tha lai var ukku ▁ne jam ave y ▁vay as a ag idu chu . . . ▁siva ji ▁than ▁tha lai var oda ▁pe ak xxunk\n",
       "y: CategoryList\n",
       "Positive ,Negative ,Mixed_feelings ,Positive ,Positive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (3149 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁yar ay ellam ▁f d f s ▁p p ga ▁ip po ve ▁re ad y ▁ag iti nga,▁x x bo s ▁enna da ▁vis wa sam ▁mer sal ▁sar kar ▁madhri ▁tim e ▁la ▁li kes ▁and ▁vi e ws ▁cr e ate ▁pann alaya e,▁x x bo s ▁yu van ▁ver a ▁le vel ▁ya ▁ xxrep ▁4 ▁ . ▁valu ab le ▁sc ri p t . ▁s k ▁in ▁a ction,▁x x bo s ▁70 ▁vay asu l ay um ▁than oda ▁rasi gar gal a ▁sand ho s apadu tha ▁ip di ▁ula iku ra ru ▁ivar a ▁po i ▁ka y apadu th ur anu ngal e ▁e cha in ga ▁ula chu ▁va al an um,▁x x bo s ▁all ▁the ▁be st ▁anna . . . te lu gu ▁ma kkal ▁selva n ▁f ans\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb5427e4d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MatthewsCorreff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mcc, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.032375</td>\n",
       "      <td>0.886263</td>\n",
       "      <td>0.184757</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first-full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.935355</td>\n",
       "      <td>0.818849</td>\n",
       "      <td>0.243696</td>\n",
       "      <td>0.703968</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (12595 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁tra il er ▁la te ▁ ah ▁parth avan ga ▁ like ▁po du nga,▁x x bo s ▁mo ve ▁pat hu tu ▁vant hu ▁tra il er ▁pa k ur v nga ▁yar u,▁x x bo s ▁put hu pe tai ▁dhan u sh ▁ ah ▁yar ellam ▁pathin ga,▁x x bo s ▁dhan u sh ▁ oda ▁chara c ter ▁ , put hu ▁sa ▁eru kay ▁ , ▁mas s ▁ ta,▁x x bo s ▁ver a ▁le vel ▁ ippa ▁pes ung ada ▁mo kka ▁nu ▁tha lai v ▁ xxrep ▁6 ▁a\n",
       "y: CategoryList\n",
       "Positive ,Positive ,Positive ,Positive ,Positive \n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (1260 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁da il y ▁li kes ▁ xxunk ▁vi e ws ▁pa kka ▁van th ava ga ▁ella ru kum ▁van ak kam,▁x x bo s ▁25 ▁k ▁dis like s ▁eth uku ▁da ▁in tha ▁tra il er ku ▁po i ▁ap di ▁un gal ukku ▁en tha ▁tra il er ▁tha ▁pi di kum,▁x x bo s ▁ xxunk ▁ ly ca ▁unna ▁ne na cha ▁pa vam a ▁iru ku ▁ya,▁x x bo s ▁it ▁l ook s ▁ like ▁hi ndi ▁mo vi e ▁ami ta b ▁ba chan,▁x x bo s ▁tha lai var ukku ▁ne jam ave y ▁vay as a ag idu chu . . . ▁siva ji ▁than ▁tha lai var oda ▁pe ak xxunk\n",
       "y: CategoryList\n",
       "Positive ,Negative ,Mixed_feelings ,Positive ,Positive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (3149 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁yar ay ellam ▁f d f s ▁p p ga ▁ip po ve ▁re ad y ▁ag iti nga,▁x x bo s ▁enna da ▁vis wa sam ▁mer sal ▁sar kar ▁madhri ▁tim e ▁la ▁li kes ▁and ▁vi e ws ▁cr e ate ▁pann alaya e,▁x x bo s ▁yu van ▁ver a ▁le vel ▁ya ▁ xxrep ▁4 ▁ . ▁valu ab le ▁sc ri p t . ▁s k ▁in ▁a ction,▁x x bo s ▁70 ▁vay asu l ay um ▁than oda ▁rasi gar gal a ▁sand ho s apadu tha ▁ip di ▁ula iku ra ru ▁ivar a ▁po i ▁ka y apadu th ur anu ngal e ▁e cha in ga ▁ula chu ▁va al an um,▁x x bo s ▁all ▁the ▁be st ▁anna . . . te lu gu ▁ma kkal ▁selva n ▁f ans\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7fb5427e4d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (12595 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁tra il er ▁la te ▁ ah ▁parth avan ga ▁ like ▁po du nga,▁x x bo s ▁mo ve ▁pat hu tu ▁vant hu ▁tra il er ▁pa k ur v nga ▁yar u,▁x x bo s ▁put hu pe tai ▁dhan u sh ▁ ah ▁yar ellam ▁pathin ga,▁x x bo s ▁dhan u sh ▁ oda ▁chara c ter ▁ , put hu ▁sa ▁eru kay ▁ , ▁mas s ▁ ta,▁x x bo s ▁ver a ▁le vel ▁ ippa ▁pes ung ada ▁mo kka ▁nu ▁tha lai v ▁ xxrep ▁6 ▁a\n",
       "y: CategoryList\n",
       "Positive ,Positive ,Positive ,Positive ,Positive \n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (1260 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁da il y ▁li kes ▁ xxunk ▁vi e ws ▁pa kka ▁van th ava ga ▁ella ru kum ▁van ak kam,▁x x bo s ▁25 ▁k ▁dis like s ▁eth uku ▁da ▁in tha ▁tra il er ku ▁po i ▁ap di ▁un gal ukku ▁en tha ▁tra il er ▁tha ▁pi di kum,▁x x bo s ▁ xxunk ▁ ly ca ▁unna ▁ne na cha ▁pa vam a ▁iru ku ▁ya,▁x x bo s ▁it ▁l ook s ▁ like ▁hi ndi ▁mo vi e ▁ami ta b ▁ba chan,▁x x bo s ▁tha lai var ukku ▁ne jam ave y ▁vay as a ag idu chu . . . ▁siva ji ▁than ▁tha lai var oda ▁pe ak xxunk\n",
       "y: CategoryList\n",
       "Positive ,Negative ,Mixed_feelings ,Positive ,Positive \n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (3149 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁yar ay ellam ▁f d f s ▁p p ga ▁ip po ve ▁re ad y ▁ag iti nga,▁x x bo s ▁enna da ▁vis wa sam ▁mer sal ▁sar kar ▁madhri ▁tim e ▁la ▁li kes ▁and ▁vi e ws ▁cr e ate ▁pann alaya e,▁x x bo s ▁yu van ▁ver a ▁le vel ▁ya ▁ xxrep ▁4 ▁ . ▁valu ab le ▁sc ri p t . ▁s k ▁in ▁a ction,▁x x bo s ▁70 ▁vay asu l ay um ▁than oda ▁rasi gar gal a ▁sand ho s apadu tha ▁ip di ▁ula iku ra ru ▁ivar a ▁po i ▁ka y apadu th ur anu ngal e ▁e cha in ga ▁ula chu ▁va al an um,▁x x bo s ▁all ▁the ▁be st ▁anna . . . te lu gu ▁ma kkal ▁selva n ▁f ans\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[MatthewsCorreff(), <function accuracy at 0x7fb5427e4d08>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False, cb_fns_registered=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('second-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.850083</td>\n",
       "      <td>0.746708</td>\n",
       "      <td>0.365137</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.839479</td>\n",
       "      <td>0.702771</td>\n",
       "      <td>0.384020</td>\n",
       "      <td>0.738889</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.893236</td>\n",
       "      <td>0.972616</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.958270</td>\n",
       "      <td>0.882259</td>\n",
       "      <td>0.187138</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.933478</td>\n",
       "      <td>0.824397</td>\n",
       "      <td>0.259833</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.896298</td>\n",
       "      <td>0.792845</td>\n",
       "      <td>0.339776</td>\n",
       "      <td>0.724603</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.863896</td>\n",
       "      <td>0.755098</td>\n",
       "      <td>0.400766</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.836132</td>\n",
       "      <td>0.722058</td>\n",
       "      <td>0.422963</td>\n",
       "      <td>0.750794</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.811084</td>\n",
       "      <td>0.709317</td>\n",
       "      <td>0.417659</td>\n",
       "      <td>0.748413</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.792862</td>\n",
       "      <td>0.706518</td>\n",
       "      <td>0.425950</td>\n",
       "      <td>0.750794</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "learn.save('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = TextClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  12, 120,   4,   3],\n",
       "       [  0,  71,  88,   2,   4],\n",
       "       [  2,  13, 833,   3,   6],\n",
       "       [  0,   0,   3,  26,   0],\n",
       "       [  0,   5,  49,   0,  14]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interp.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mixed_feelings ': 0,\n",
       " 'Negative ': 1,\n",
       " 'Positive ': 2,\n",
       " 'not-Tamil ': 3,\n",
       " 'unknown_state ': 4}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.c2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>unknown_state</th>\n",
       "      <th>Positive</th>\n",
       "      <th>not-Tamil</th>\n",
       "      <th>Mixed_feelings</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daily likes &amp; views pakka vanthavaga ellaruku...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0902639</td>\n",
       "      <td>0.748242</td>\n",
       "      <td>0.00104036</td>\n",
       "      <td>0.0956726</td>\n",
       "      <td>0.064781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25 k dislikes ethuku da intha trailerku poi a...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0468466</td>\n",
       "      <td>0.307581</td>\n",
       "      <td>0.00121287</td>\n",
       "      <td>0.156031</td>\n",
       "      <td>0.488329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Lyca unna nenacha pavama iruku ya</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0140259</td>\n",
       "      <td>0.674023</td>\n",
       "      <td>0.00366425</td>\n",
       "      <td>0.13598</td>\n",
       "      <td>0.172307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It looks like Hindi movie amitab bachan</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0965051</td>\n",
       "      <td>0.377914</td>\n",
       "      <td>0.123414</td>\n",
       "      <td>0.155451</td>\n",
       "      <td>0.246716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thalaivarukku nejamavey vayasaagiduchu... siv...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0146662</td>\n",
       "      <td>0.791409</td>\n",
       "      <td>0.000865942</td>\n",
       "      <td>0.104964</td>\n",
       "      <td>0.0880947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query     actual_label  \\\n",
       "0   Daily likes & views pakka vanthavaga ellaruku...        Positive    \n",
       "1   25 k dislikes ethuku da intha trailerku poi a...        Negative    \n",
       "2                 #Lyca unna nenacha pavama iruku ya  Mixed_feelings    \n",
       "3            It looks like Hindi movie amitab bachan        Positive    \n",
       "4   Thalaivarukku nejamavey vayasaagiduchu... siv...        Positive    \n",
       "\n",
       "  predicted_label unknown_state  Positive    not-Tamil  Mixed_feelings   \\\n",
       "0       Positive       0.0902639  0.748242   0.00104036       0.0956726   \n",
       "1       Negative       0.0468466  0.307581   0.00121287        0.156031   \n",
       "2       Positive       0.0140259  0.674023   0.00366425         0.13598   \n",
       "3       Positive       0.0965051  0.377914     0.123414        0.155451   \n",
       "4       Positive       0.0146662  0.791409  0.000865942        0.104964   \n",
       "\n",
       "   Negative   \n",
       "0   0.064781  \n",
       "1   0.488329  \n",
       "2   0.172307  \n",
       "3   0.246716  \n",
       "4  0.0880947  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_valid.copy()\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'query': list(df_test['text']), 'actual_label': list(df_test['category']), 'predicted_label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train['category']))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Valid, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    row['predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7507936507936508"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42595047453467916"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.688700482720738"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_result['actual_label'], df_result['predicted_label'], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>unknown_state</th>\n",
       "      <th>Positive</th>\n",
       "      <th>not-Tamil</th>\n",
       "      <th>Mixed_feelings</th>\n",
       "      <th>Negative</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Lyca unna nenacha pavama iruku ya</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0140259</td>\n",
       "      <td>0.674023</td>\n",
       "      <td>0.00366425</td>\n",
       "      <td>0.13598</td>\n",
       "      <td>0.172307</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vera levellllllllllllll all the best shankar ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0101191</td>\n",
       "      <td>0.899275</td>\n",
       "      <td>0.00083147</td>\n",
       "      <td>0.0586485</td>\n",
       "      <td>0.0311261</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HELLO YOUTUBE TRENT ON1 BUTTON YOUR SOFTWARE ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.106255</td>\n",
       "      <td>0.624435</td>\n",
       "      <td>0.0382924</td>\n",
       "      <td>0.0996062</td>\n",
       "      <td>0.131412</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Superstar Rajnikant Fans Hit Like  2K Likes  ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0384124</td>\n",
       "      <td>0.878994</td>\n",
       "      <td>0.00105333</td>\n",
       "      <td>0.0585051</td>\n",
       "      <td>0.0230351</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Vaa thaliva vaa thalaiva Marana mass thailaiv...</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0111512</td>\n",
       "      <td>0.845636</td>\n",
       "      <td>0.000533368</td>\n",
       "      <td>0.092808</td>\n",
       "      <td>0.0498719</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>life time viewae 11m thaandathu pola. kodumai.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.119291</td>\n",
       "      <td>0.518008</td>\n",
       "      <td>0.00137219</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.191769</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>Yenakku mattum than iru mugan movie  Maari th...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0509016</td>\n",
       "      <td>0.32762</td>\n",
       "      <td>0.0270263</td>\n",
       "      <td>0.230979</td>\n",
       "      <td>0.363473</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>ವಿಂಟೆಜ್  ರಜ್ನೀ... Karnataka rajnj fans hit. Like</td>\n",
       "      <td>not-Tamil</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.19143</td>\n",
       "      <td>0.606134</td>\n",
       "      <td>0.0738548</td>\n",
       "      <td>0.0803482</td>\n",
       "      <td>0.0482327</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>Style la irukana hahaha mass dialogue</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0273858</td>\n",
       "      <td>0.786842</td>\n",
       "      <td>0.0403217</td>\n",
       "      <td>0.0918596</td>\n",
       "      <td>0.0535909</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Like for lokesh kanagaraj THALAPATHY 64 Director</td>\n",
       "      <td>unknown_state</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.309506</td>\n",
       "      <td>0.414332</td>\n",
       "      <td>0.0144804</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.126481</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query     actual_label  \\\n",
       "2                    #Lyca unna nenacha pavama iruku ya  Mixed_feelings    \n",
       "7      Vera levellllllllllllll all the best shankar ...        Negative    \n",
       "13     HELLO YOUTUBE TRENT ON1 BUTTON YOUR SOFTWARE ...        Negative    \n",
       "20     Superstar Rajnikant Fans Hit Like  2K Likes  ...        Negative    \n",
       "26     Vaa thaliva vaa thalaiva Marana mass thailaiv...  Mixed_feelings    \n",
       "...                                                 ...              ...   \n",
       "1247     life time viewae 11m thaandathu pola. kodumai.        Negative    \n",
       "1251   Yenakku mattum than iru mugan movie  Maari th...        Positive    \n",
       "1253   ವಿಂಟೆಜ್  ರಜ್ನೀ... Karnataka rajnj fans hit. Like       not-Tamil    \n",
       "1257              Style la irukana hahaha mass dialogue        Negative    \n",
       "1258   Like for lokesh kanagaraj THALAPATHY 64 Director   unknown_state    \n",
       "\n",
       "     predicted_label unknown_state  Positive    not-Tamil  Mixed_feelings   \\\n",
       "2          Positive       0.0140259  0.674023   0.00366425         0.13598   \n",
       "7          Positive       0.0101191  0.899275   0.00083147       0.0586485   \n",
       "13         Positive        0.106255  0.624435    0.0382924       0.0996062   \n",
       "20         Positive       0.0384124  0.878994   0.00105333       0.0585051   \n",
       "26         Positive       0.0111512  0.845636  0.000533368        0.092808   \n",
       "...              ...            ...       ...          ...             ...   \n",
       "1247       Positive        0.119291  0.518008   0.00137219        0.169559   \n",
       "1251       Negative       0.0509016   0.32762    0.0270263        0.230979   \n",
       "1253       Positive         0.19143  0.606134    0.0738548       0.0803482   \n",
       "1257       Positive       0.0273858  0.786842    0.0403217       0.0918596   \n",
       "1258       Positive        0.309506  0.414332    0.0144804          0.1352   \n",
       "\n",
       "      Negative   status  \n",
       "2      0.172307   False  \n",
       "7     0.0311261   False  \n",
       "13     0.131412   False  \n",
       "20    0.0230351   False  \n",
       "26    0.0498719   False  \n",
       "...         ...     ...  \n",
       "1247   0.191769   False  \n",
       "1251   0.363473   False  \n",
       "1253  0.0482327   False  \n",
       "1257  0.0535909   False  \n",
       "1258   0.126481   False  \n",
       "\n",
       "[314 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['status'] = df_result['actual_label']==df_result['predicted_label']\n",
    "df_result[df_result['status']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[(df_result['status'] == False) & (df_result['predicted_label'] == 'Positive ') & (df_result['Positive '] < 0.7)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>unknown_state</th>\n",
       "      <th>Positive</th>\n",
       "      <th>not-Tamil</th>\n",
       "      <th>Mixed_feelings</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ta_sent_1</td>\n",
       "      <td>Yarayellam FDFS ppga ippove ready agitinga</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>0.684897</td>\n",
       "      <td>0.00102912</td>\n",
       "      <td>0.0983007</td>\n",
       "      <td>0.0949456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ta_sent_2</td>\n",
       "      <td>Ennada viswasam mersal sarkar madhri time la l...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0659945</td>\n",
       "      <td>0.271631</td>\n",
       "      <td>0.00269051</td>\n",
       "      <td>0.24773</td>\n",
       "      <td>0.411954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ta_sent_3</td>\n",
       "      <td>yuvan vera level ya .... valuable script. SK i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.00169345</td>\n",
       "      <td>0.942566</td>\n",
       "      <td>0.000100132</td>\n",
       "      <td>0.0397426</td>\n",
       "      <td>0.0158974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ta_sent_4</td>\n",
       "      <td>70 vayasulayum thanoda rasigargala sandhosapad...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0177472</td>\n",
       "      <td>0.548892</td>\n",
       "      <td>0.00193056</td>\n",
       "      <td>0.157654</td>\n",
       "      <td>0.273776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ta_sent_5</td>\n",
       "      <td>all the best anna...Telugu makkal selvan fans</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.562273</td>\n",
       "      <td>0.0903013</td>\n",
       "      <td>0.11538</td>\n",
       "      <td>0.132389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text   category  \\\n",
       "0  ta_sent_1         Yarayellam FDFS ppga ippove ready agitinga  Positive    \n",
       "1  ta_sent_2  Ennada viswasam mersal sarkar madhri time la l...  Negative    \n",
       "2  ta_sent_3  yuvan vera level ya .... valuable script. SK i...  Positive    \n",
       "3  ta_sent_4  70 vayasulayum thanoda rasigargala sandhosapad...  Positive    \n",
       "4  ta_sent_5      all the best anna...Telugu makkal selvan fans  Positive    \n",
       "\n",
       "  unknown_state  Positive    not-Tamil  Mixed_feelings   Negative   \n",
       "0       0.120828  0.684897   0.00102912       0.0983007  0.0949456  \n",
       "1      0.0659945  0.271631   0.00269051         0.24773   0.411954  \n",
       "2     0.00169345  0.942566  0.000100132       0.0397426  0.0158974  \n",
       "3      0.0177472  0.548892   0.00193056        0.157654   0.273776  \n",
       "4       0.099657  0.562273    0.0903013         0.11538   0.132389  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(path/'../dc_fire/tamil_test.tsv', sep='\\t')\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'id': list(df_test['id']), 'text': list(df_test['text']), 'category': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train['category']))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        row[node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    row['category'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2735, 8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[df_result['category']=='Positive '].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('test_res_dc_fire_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
