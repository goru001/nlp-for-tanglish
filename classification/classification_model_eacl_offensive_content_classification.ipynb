{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import pdb\n",
    "import random\n",
    "from fastai.imports import *\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, matthews_corrcoef, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.60', '1.7.1', '0.2.7')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch, fastprogress\n",
    "fastai.__version__ , torch.__version__, fastprogress.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)  \n",
    "    torch.manual_seed(seed_value)  \n",
    "    random.seed(seed_value)\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  \n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"home/temp/data/eacl/ta/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f\"{BASE_DIR}/tamil_offensive_full_train_transliterated.csv\")\n",
    "df_train.dropna(inplace=True)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35139, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 25425, 4: 1454, 5: 454, 3: 2557, 1: 2906, 2: 2343})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Handsome hunk keri vaa thalaivaa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thenkaachi maavattam naataar chamuthaayam chaa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je vous aime bravo pour clip de merde que j éc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chirappu melum ithu poonra pataippukal mika av...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vera level BGM  ..semma trailer.  🤞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0                  Handsome hunk keri vaa thalaivaa       0\n",
       "1  thenkaachi maavattam naataar chamuthaayam chaa...      0\n",
       "2  je vous aime bravo pour clip de merde que j éc...      4\n",
       "3  chirappu melum ithu poonra pataippukal mika av...      0\n",
       "4                Vera level BGM  ..semma trailer.  🤞      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv(f\"{BASE_DIR}/temp/data/eacl/ta/tamil_offensive_full_dev_transliterated.csv\")\n",
    "df_valid.dropna(inplace=True)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.12.2018epo trailer pathutu irken  ...Semay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paka thana poro movie la Enna irukunu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“U kena tunggu lebih lama lagi untuk tahu saya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suriya anna vera level anna mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0   14.12.2018epo trailer pathutu irken  ...Semay...\n",
       "1             Paka thana poro movie la Enna irukunu \n",
       "2  “U kena tunggu lebih lama lagi untuk tahu saya...\n",
       "3                  Suriya anna vera level anna mass \n",
       "4  suma kaththaatha da sound over a pooda kudaath..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(f\"{BASE_DIR}/temp/data/eacl/ta/tamil_offensive_full_test_transliterated.csv\")\n",
    "df_test.dropna(inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35139, 2), (4388, 2), (4392, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 25425, 4: 1454, 5: 454, 3: 2557, 1: 2906, 2: 2343}),\n",
       " Counter({0: 3193, 4: 172, 3: 295, 2: 307, 1: 356, 5: 65}))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_train['label']), Counter(df_valid['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['label']\n",
    "text_cols = ['sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization + Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_all_caps(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = replace_all_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def handle_upper_case_first_letter(t: str) -> str:\n",
    "    tokens = t.split()\n",
    "    tokens = deal_caps(tokens)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def lower_case_everything(t: str) -> str:\n",
    "    return t.lower().replace('@user', '').replace('#tag ', '').replace('rt ', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMixedTamilTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lang:str):\n",
    "        self.lang = lang\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(str(path/\"../models/taen_spm.model\"))\n",
    "        \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../models/taen_spm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(8000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxpad',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " '.',\n",
       " ',',\n",
       " '▁',\n",
       " 's',\n",
       " 'a',\n",
       " '=\"',\n",
       " 'in',\n",
       " 'doc',\n",
       " 't',\n",
       " 'il',\n",
       " 'i']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8,000 is the vocab size that we chose in sentencepiece\n",
    "taen_vocab = Vocab(itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lang='taen', tok_func=CodeMixedTamilTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_rules.append(lower_case_everything)\n",
    "tokenizer.pre_rules.append(handle_all_caps)\n",
    "tokenizer.pre_rules.append(handle_upper_case_first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxunk',\n",
       "  'xxpad',\n",
       "  'xxbos',\n",
       "  'xxeos',\n",
       "  'xxfld',\n",
       "  'xxmaj',\n",
       "  'xxup',\n",
       "  'xxrep',\n",
       "  'xxwrep'],\n",
       " [<function fastai.text.transform.fix_html(x: str) -> str>,\n",
       "  <function fastai.text.transform.replace_rep(t: str) -> str>,\n",
       "  <function fastai.text.transform.replace_wrep(t: str) -> str>,\n",
       "  <function fastai.text.transform.spec_add_spaces(t: str) -> str>,\n",
       "  <function fastai.text.transform.rm_useless_spaces(t: str) -> str>,\n",
       "  <function __main__.lower_case_everything(t: str) -> str>,\n",
       "  <function __main__.handle_all_caps(t: str) -> str>,\n",
       "  <function __main__.handle_upper_case_first_letter(t: str) -> str>],\n",
       " [<function fastai.text.transform.replace_all_caps(x: Collection[str]) -> Collection[str]>,\n",
       "  <function fastai.text.transform.deal_caps(x: Collection[str]) -> Collection[str]>])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('▁epo▁trailer▁pathutu▁irken',\n",
       " [['▁e', 'po', '▁tra', 'il', 'er', '▁pat', 'hu', 'tu', '▁ir', 'ken']])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.process_all(['epo trailer pathutu irken '])\n",
    "''.join(tokens[0]), tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(a, dtype=dtype, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextLMDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=taen_vocab, label_cols=['label'], text_cols=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . . ▁x x bo s ▁kav un tar ▁the var . cha ar pa ak a ▁ver ri ▁per a ▁va a z h th th ukk al ▁ xxunk ▁x x bo s ▁ip po ▁in tha ▁tra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁irukkum ▁unmai ya ana ▁naatak ak ▁ka a thal ▁vish ay ath th ai ▁cho n na al ▁at hu ▁cha ath ip ▁pat am ▁av lo o tha an ▁cha ar ▁poor a al e es ▁x x bo s ▁tamil ▁cinema ▁mon ster ▁surya ▁ xxrep ▁4 ▁ . ▁x x bo s ▁b g m ▁king ▁yu van ▁shankar ▁raja ▁x x bo s ▁pa kka ▁mas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>? ▁tha lai var : s we et ▁sa ap ida ▁por om . . . ▁ver a ▁le vel . . . ▁x x bo s ▁at li ▁math i ri ▁mutt al u kal ▁kan du ▁padi kkat tum ▁e ppa di ▁padam ▁pud ikk anam ▁en tra th ▁x x bo s ▁vay as ukku ▁tha gu ndha ▁kel vi ▁ya ▁ke kka ▁sol lu nga ▁da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁x x bo s ▁kon g ku ▁cham u tha ay ath th inar ▁cha ar pa ak a ▁pat am ▁ver ri ▁per a ▁va a z h th th ukk al ▁x x bo s ▁ka agam ▁karai ndhu ▁ko odi ▁unn um , ▁mani dham ▁en num ▁mood ar ▁ko o dam ▁ko odi ▁ser dhu ▁pa ga i mai ▁kollum . . . ▁id il ▁yaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁nadi ku ran u ▁ka ko os ▁ar my ▁ko ov un anu nga ▁ xxunk ▁x x bo s ▁ ng k ▁was ▁in s pi red ▁to ▁ nt k ▁i ▁thi n k . ▁se e man ▁illamal ▁aras iyal um ▁illa i ▁ , arasi yal ▁padam um ▁illa i ▁nu ▁puri u dhu . . . ▁x x bo s ▁parv aiye e ▁ver a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./../models/models/best_model'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{path}/../models/models/best_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (35139 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁kav un tar ▁the var . cha ar pa ak a ▁ver ri ▁per a ▁va a z h th th ukk al ▁ xxunk\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (4388 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁the n ka a chi ▁ma av attam ▁na a ta ar ▁cham u tha ayam ▁cha ar pa ak a ▁va a z h th th ukk al,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁chir ap pu ▁melum ▁it hu ▁poon ra ▁pat ai ppu kal ▁mik a ▁ava chi yam,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . s em ma ▁tra il er . ▁ xxunk\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (4388 items)\n",
       "x: LMTextList\n",
       "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁the n ka a chi ▁ma av attam ▁na a ta ar ▁cham u tha ayam ▁cha ar pa ak a ▁va a z h th th ukk al,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁chir ap pu ▁melum ▁it hu ▁poon ra ▁pat ai ppu kal ▁mik a ▁ava chi yam,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . s em ma ▁tra il er . ▁ xxunk\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(8000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1152, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1152, 1152, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1152, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f82b5183ca0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(f\"{BASE_DIR}/temp/models/best_model\", with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.044744</td>\n",
       "      <td>3.922262</td>\n",
       "      <td>0.326730</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.737872</td>\n",
       "      <td>3.653384</td>\n",
       "      <td>0.361356</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.440274</td>\n",
       "      <td>3.375876</td>\n",
       "      <td>0.398717</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.251985</td>\n",
       "      <td>3.262846</td>\n",
       "      <td>0.412751</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.197981</td>\n",
       "      <td>3.221164</td>\n",
       "      <td>0.418171</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.154185</td>\n",
       "      <td>3.215180</td>\n",
       "      <td>0.419078</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned', with_opt=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paka thana ▁it hu ▁naan ▁a ka ▁matt er ha ▁chinna ▁ra'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Paka thana',n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(a, dtype=dtype, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "data_clas = TextClasDataBunch.from_df(path=path, train_df=df_train, valid_df=df_valid, test_df=df_test, tokenizer=tokenizer, vocab=taen_vocab, bs=16, label_cols=['label'], text_cols=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁thi ro u pathi ▁ xxrep ▁10 ▁= ▁mann ai y um ▁penn ai y um ▁ka ak ka ▁vant ha ▁na aya ki ▁naatak a ▁ka ath alai ▁tho ol ur ikkum ▁nav een a ▁thi ro u pathi ▁pin j chil ▁pa z hu th tha a ▁ve m pi ▁tha an ▁va atum ▁nan j ch ai ▁chu vai th tha al ▁maranam</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁en ta a ▁e ena ▁pir avi kala a ▁avan ▁avan ▁ path th u ▁ma ach am ▁chu man th u ▁kash tap pattu ▁valar ath th u ▁tha an ▁aa ch ai ▁patta th tha ▁anup avi kka atti y um ▁than ▁ku z han th ai ▁ kku ▁the va iya ana tha ▁va ang ki ▁ku tu th th u ▁aa ch</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁anai th th u ▁cham ook a ▁ mak kalin ▁ka aman ts ▁ ith ai ▁pa ar kkum ▁po z hu th u ▁on ru ▁the li va ak a ▁puri kir ath u ▁oru ▁kuripp it ta ▁cham ook ath tha al ▁mar ra ▁anai th th u ▁cham ook amum ▁en tha ▁alav irku ▁pa ath ippu ▁at aint hu ▁irukki rat hu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁ ith ula ▁enna ▁ka am e tin na a ▁oru ▁ pakk am ▁na ang ka ▁aan ta ▁param parai ▁pen ta ▁param para in nu ▁mee ch aiya i ▁mu rukk ur avan um ▁inno ru ▁ pakk am ▁at ang ka ▁maru ▁ ath th u ▁mee ru n nu ▁kam pu ▁chu th th ur avan um ▁50 varu sha ma a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>▁x x bo s ▁vanni ya ▁kul a ▁k sh ath thi ri yar ▁( ak ni ▁kul a ▁k sh ath thi ri yar ▁ma kkal ▁ku tum path thil ▁ull a ▁vevveru ▁pattam ▁kont a ▁vanni yar kal ▁ xxunk van n iya ▁kav un tar ▁ xxunk van n iya ▁pat aiya atchi ▁ xxunk van n iya ▁na aya kar ▁ xxunk van n iya ▁va</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "data_clas.sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (35139 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁kav un tar ▁the var . cha ar pa ak a ▁ver ri ▁per a ▁va a z h th th ukk al ▁ xxunk\n",
       "y: CategoryList\n",
       "0,4,0,0,0\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (4388 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁the n ka a chi ▁ma av attam ▁na a ta ar ▁cham u tha ayam ▁cha ar pa ak a ▁va a z h th th ukk al,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁chir ap pu ▁melum ▁it hu ▁poon ra ▁pat ai ppu kal ▁mik a ▁ava chi yam,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . s em ma ▁tra il er . ▁ xxunk\n",
       "y: CategoryList\n",
       "0,0,4,0,0\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (4388 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁the n ka a chi ▁ma av attam ▁na a ta ar ▁cham u tha ayam ▁cha ar pa ak a ▁va a z h th th ukk al,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁chir ap pu ▁melum ▁it hu ▁poon ra ▁pat ai ppu kal ▁mik a ▁ava chi yam,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . s em ma ▁tra il er . ▁ xxunk\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f82b5183ca0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = MatthewsCorreff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = [mcc, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.751917</td>\n",
       "      <td>0.263278</td>\n",
       "      <td>0.749772</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first-full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.750675</td>\n",
       "      <td>0.682011</td>\n",
       "      <td>0.381225</td>\n",
       "      <td>0.770283</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>matthews_correff</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.658494</td>\n",
       "      <td>0.677764</td>\n",
       "      <td>0.412541</td>\n",
       "      <td>0.774385</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.657779</td>\n",
       "      <td>0.670823</td>\n",
       "      <td>0.418215</td>\n",
       "      <td>0.778943</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.656074</td>\n",
       "      <td>0.658323</td>\n",
       "      <td>0.427029</td>\n",
       "      <td>0.778259</td>\n",
       "      <td>00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.615710</td>\n",
       "      <td>0.652915</td>\n",
       "      <td>0.439312</td>\n",
       "      <td>0.778259</td>\n",
       "      <td>00:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.521762</td>\n",
       "      <td>0.662419</td>\n",
       "      <td>0.452026</td>\n",
       "      <td>0.773473</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.7743846774101257.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 1 with accuracy value: 0.7789425849914551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='final')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (35139 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁kav un tar ▁the var . cha ar pa ak a ▁ver ri ▁per a ▁va a z h th th ukk al ▁ xxunk\n",
       "y: CategoryList\n",
       "0,4,0,0,0\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (4388 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁the n ka a chi ▁ma av attam ▁na a ta ar ▁cham u tha ayam ▁cha ar pa ak a ▁va a z h th th ukk al,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁chir ap pu ▁melum ▁it hu ▁poon ra ▁pat ai ppu kal ▁mik a ▁ava chi yam,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . s em ma ▁tra il er . ▁ xxunk\n",
       "y: CategoryList\n",
       "0,0,4,0,0\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (4388 items)\n",
       "x: TextList\n",
       "▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁the n ka a chi ▁ma av attam ▁na a ta ar ▁cham u tha ayam ▁cha ar pa ak a ▁va a z h th th ukk al,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁chir ap pu ▁melum ▁it hu ▁poon ra ▁pat ai ppu kal ▁mik a ▁ava chi yam,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . s em ma ▁tra il er . ▁ xxunk\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ., model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(8000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(8000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fad60922ca0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(8000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(8000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Handsome hunk keri vaa thalaivaa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.954507</td>\n",
       "      <td>0.029217</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.002211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thenkaachi maavattam naataar chamuthaayam chaa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994352</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je vous aime bravo pour clip de merde que j éc...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>0.059537</td>\n",
       "      <td>0.077506</td>\n",
       "      <td>0.044610</td>\n",
       "      <td>0.438532</td>\n",
       "      <td>0.010714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chirappu melum ithu poonra pataippukal mika av...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955425</td>\n",
       "      <td>0.006989</td>\n",
       "      <td>0.008612</td>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vera level BGM  ..semma trailer.  🤞</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932819</td>\n",
       "      <td>0.041869</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.016839</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.002203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  actual_label  \\\n",
       "0                  Handsome hunk keri vaa thalaivaa              0   \n",
       "1  thenkaachi maavattam naataar chamuthaayam chaa...             0   \n",
       "2  je vous aime bravo pour clip de merde que j éc...             4   \n",
       "3  chirappu melum ithu poonra pataippukal mika av...             0   \n",
       "4                Vera level BGM  ..semma trailer.  🤞             0   \n",
       "\n",
       "  predicted_label         0         1         2         3         4         5  \n",
       "0               0  0.954507  0.029217  0.006231  0.005025  0.002808  0.002211  \n",
       "1               0  0.994352  0.001518  0.001340  0.002317  0.000093  0.000379  \n",
       "2               4  0.369100  0.059537  0.077506  0.044610  0.438532  0.010714  \n",
       "3               0  0.955425  0.006989  0.008612  0.027626  0.000042  0.001306  \n",
       "4               0  0.932819  0.041869  0.003310  0.016839  0.002960  0.002203  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_valid.copy()\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
    "df_dict = {'query': list(df_test['sentence']), 'actual_label': list(df_test['label']), 'predicted_label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_valid['label']))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "    \n",
    "df_result = pd.DataFrame(df_dict)\n",
    "preds = learn.get_preds(ds_type=DatasetType.Valid, ordered=True)\n",
    "nodes = []\n",
    "predicted_labels = []\n",
    "for index, row in df_result.iterrows():\n",
    "    for node in all_nodes:\n",
    "        df_result.loc[index, node] = preds[0][index][learn.data.c2i[node]].item()\n",
    "    df_result.loc[index, 'predicted_label'] = i2c[np.argmax(preds[0][index]).data.item()]\n",
    "\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "df_result['predicted_label'] = df_result['predicted_label'].astype(int)\n",
    "df_result['actual_label'] = df_result['actual_label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.int64, numpy.int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_result['actual_label'].values[0]), type(df_result['predicted_label'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7782588878760255"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_result['actual_label'], df_result['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4163069605014294"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(df_result['actual_label'], df_result['predicted_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7335403148302653"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_result['actual_label'], df_result['predicted_label'], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/temp_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7269861245612425, 0.7782588878760255, 0.7335403148302653, None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(df_result['actual_label'], df_result['predicted_label'], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dei YENDA ungalukku inthe illatha Vella Surya ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354947</td>\n",
       "      <td>0.263264</td>\n",
       "      <td>0.204207</td>\n",
       "      <td>0.132686</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>0.036443</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>thala innum ipdi full white evvalavu naal nadi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887194</td>\n",
       "      <td>0.032376</td>\n",
       "      <td>0.036545</td>\n",
       "      <td>0.037426</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Deii ponga da tamil naatla rape crime increase...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467927</td>\n",
       "      <td>0.080725</td>\n",
       "      <td>0.038836</td>\n",
       "      <td>0.393410</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.018398</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Comment la en da picha edukuringa... pichakara...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049569</td>\n",
       "      <td>0.548068</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.331396</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Karthi fanslike Kaithi waiting but bigil maran...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395608</td>\n",
       "      <td>0.056239</td>\n",
       "      <td>0.394572</td>\n",
       "      <td>0.133157</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>Ivarukkku eppodhum thalaivar kalaigner lightaa...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369844</td>\n",
       "      <td>0.208622</td>\n",
       "      <td>0.288573</td>\n",
       "      <td>0.035840</td>\n",
       "      <td>0.075511</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4372</th>\n",
       "      <td>Trailer Nala irukanu oru than comment pandranu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812631</td>\n",
       "      <td>0.129006</td>\n",
       "      <td>0.018768</td>\n",
       "      <td>0.032908</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>Wigpathy Visay na Padam Flop than ithula Kabal...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035182</td>\n",
       "      <td>0.140930</td>\n",
       "      <td>0.071759</td>\n",
       "      <td>0.697300</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>Vikram ella styleum set aaguthu.. Namba moonji...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.426659</td>\n",
       "      <td>0.214986</td>\n",
       "      <td>0.234326</td>\n",
       "      <td>0.094319</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>8k dislike sure all vijay fans</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455578</td>\n",
       "      <td>0.202949</td>\n",
       "      <td>0.059076</td>\n",
       "      <td>0.220694</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.053432</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>970 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  actual_label  \\\n",
       "17    dei YENDA ungalukku inthe illatha Vella Surya ...             2   \n",
       "21    thala innum ipdi full white evvalavu naal nadi...             2   \n",
       "27    Deii ponga da tamil naatla rape crime increase...             3   \n",
       "36    Comment la en da picha edukuringa... pichakara...             3   \n",
       "40    Karthi fanslike Kaithi waiting but bigil maran...             2   \n",
       "...                                                 ...           ...   \n",
       "4369  Ivarukkku eppodhum thalaivar kalaigner lightaa...             2   \n",
       "4372  Trailer Nala irukanu oru than comment pandranu...             1   \n",
       "4378  Wigpathy Visay na Padam Flop than ithula Kabal...             2   \n",
       "4380  Vikram ella styleum set aaguthu.. Namba moonji...             2   \n",
       "4385                    8k dislike sure all vijay fans              5   \n",
       "\n",
       "      predicted_label         0         1         2         3         4  \\\n",
       "17                  0  0.354947  0.263264  0.204207  0.132686  0.008453   \n",
       "21                  0  0.887194  0.032376  0.036545  0.037426  0.000109   \n",
       "27                  0  0.467927  0.080725  0.038836  0.393410  0.000704   \n",
       "36                  1  0.049569  0.548068  0.007857  0.331396  0.001707   \n",
       "40                  0  0.395608  0.056239  0.394572  0.133157  0.003005   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "4369                0  0.369844  0.208622  0.288573  0.035840  0.075511   \n",
       "4372                0  0.812631  0.129006  0.018768  0.032908  0.000238   \n",
       "4378                3  0.035182  0.140930  0.071759  0.697300  0.003162   \n",
       "4380                0  0.426659  0.214986  0.234326  0.094319  0.004637   \n",
       "4385                0  0.455578  0.202949  0.059076  0.220694  0.008270   \n",
       "\n",
       "             5  status  \n",
       "17    0.036443   False  \n",
       "21    0.006349   False  \n",
       "27    0.018398   False  \n",
       "36    0.061404   False  \n",
       "40    0.017420   False  \n",
       "...        ...     ...  \n",
       "4369  0.021610   False  \n",
       "4372  0.006449   False  \n",
       "4378  0.051667   False  \n",
       "4380  0.025073   False  \n",
       "4385  0.053432   False  \n",
       "\n",
       "[970 rows x 10 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['status'] = df_result['actual_label'] == df_result['predicted_label']\n",
    "df_result[df_result['status'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(f\"{BASE_DIR}/tamil_valid_results_umlfit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4392, 1)\n",
      "(4392, 1)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(f\"{BASE_DIR}/tamil_offensive_full_test_transliterated.csv\")\n",
    "print(df_test.shape)\n",
    "df_test.dropna(inplace=True)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.12.2018epo trailer pathutu irken  ...Semay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paka thana poro movie la Enna irukunu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“U kena tunggu lebih lama lagi untuk tahu saya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suriya anna vera level anna mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>mannu ponnu rentume onnu athula evan kaiya vac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>Babu mele ko ye song sunke kuch yesa feel hua ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>asuran= aadukalam+pudupettai+ wada chennai..ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>Vijay's all movies look like same.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>Eh Idhu  96,yaara emathuringa.. Bangam ji Bang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4392 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence\n",
       "0      14.12.2018epo trailer pathutu irken  ...Semay...\n",
       "1                Paka thana poro movie la Enna irukunu \n",
       "2     “U kena tunggu lebih lama lagi untuk tahu saya...\n",
       "3                     Suriya anna vera level anna mass \n",
       "4     suma kaththaatha da sound over a pooda kudaath...\n",
       "...                                                 ...\n",
       "4387  mannu ponnu rentume onnu athula evan kaiya vac...\n",
       "4388  Babu mele ko ye song sunke kuch yesa feel hua ...\n",
       "4389  asuran= aadukalam+pudupettai+ wada chennai..ye...\n",
       "4390                Vijay's all movies look like same. \n",
       "4391  Eh Idhu  96,yaara emathuringa.. Bangam ji Bang...\n",
       "\n",
       "[4392 rows x 1 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'sentence': list(df_test['sentence']), 'label': ['']*df_test.shape[0]}\n",
    "all_nodes = list(set(df_train['label']))\n",
    "for node in all_nodes:\n",
    "    df_dict[node] = ['']*df_test.shape[0]\n",
    "    \n",
    "i2c = {}\n",
    "for key, value in learn.data.c2i.items():\n",
    "    i2c[value] = key\n",
    "\n",
    "df_result = pd.DataFrame(df_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.12.2018epo trailer pathutu irken  ...Semay...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paka thana poro movie la Enna irukunu</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“U kena tunggu lebih lama lagi untuk tahu saya...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suriya anna vera level anna mass</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>mannu ponnu rentume onnu athula evan kaiya vac...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>Babu mele ko ye song sunke kuch yesa feel hua ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>asuran= aadukalam+pudupettai+ wada chennai..ye...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>Vijay's all movies look like same.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>Eh Idhu  96,yaara emathuringa.. Bangam ji Bang...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence label 0  1  2  3  4   \\\n",
       "0      14.12.2018epo trailer pathutu irken  ...Semay...                        \n",
       "1                Paka thana poro movie la Enna irukunu                         \n",
       "2     “U kena tunggu lebih lama lagi untuk tahu saya...                        \n",
       "3                     Suriya anna vera level anna mass                         \n",
       "4     suma kaththaatha da sound over a pooda kudaath...                        \n",
       "...                                                 ...   ... .. .. .. .. ..   \n",
       "4387  mannu ponnu rentume onnu athula evan kaiya vac...                        \n",
       "4388  Babu mele ko ye song sunke kuch yesa feel hua ...                        \n",
       "4389  asuran= aadukalam+pudupettai+ wada chennai..ye...                        \n",
       "4390                Vijay's all movies look like same.                         \n",
       "4391  Eh Idhu  96,yaara emathuringa.. Bangam ji Bang...                        \n",
       "\n",
       "     5   \n",
       "0        \n",
       "1        \n",
       "2        \n",
       "3        \n",
       "4        \n",
       "...  ..  \n",
       "4387     \n",
       "4388     \n",
       "4389     \n",
       "4390     \n",
       "4391     \n",
       "\n",
       "[4392 rows x 8 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.12.2018epo trailer pathutu irken  ...Semay...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.737698</td>\n",
       "      <td>0.207027</td>\n",
       "      <td>0.018546</td>\n",
       "      <td>0.027930</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.006987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paka thana poro movie la Enna irukunu</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596777</td>\n",
       "      <td>0.275670</td>\n",
       "      <td>0.031983</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.024484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“U kena tunggu lebih lama lagi untuk tahu saya...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.992902</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suriya anna vera level anna mass</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995216</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.079670</td>\n",
       "      <td>0.115144</td>\n",
       "      <td>0.590439</td>\n",
       "      <td>0.189508</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.023356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence label         0  \\\n",
       "0   14.12.2018epo trailer pathutu irken  ...Semay...     0  0.737698   \n",
       "1             Paka thana poro movie la Enna irukunu      0  0.596777   \n",
       "2  “U kena tunggu lebih lama lagi untuk tahu saya...     4  0.005738   \n",
       "3                  Suriya anna vera level anna mass      0  0.995216   \n",
       "4  suma kaththaatha da sound over a pooda kudaath...     2  0.079670   \n",
       "\n",
       "          1         2         3         4         5  \n",
       "0  0.207027  0.018546  0.027930  0.001813  0.006987  \n",
       "1  0.275670  0.031983  0.070101  0.000985  0.024484  \n",
       "2  0.000338  0.000252  0.000648  0.992902  0.000122  \n",
       "3  0.000994  0.000411  0.002299  0.000804  0.000275  \n",
       "4  0.115144  0.590439  0.189508  0.001885  0.023356  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in df_result.iterrows():\n",
    "    result = learn.predict(row['sentence'])\n",
    "    prob =  result[2]\n",
    "    for node in all_nodes:\n",
    "        df_result.loc[index, node] = prob[learn.data.c2i[node]].item()\n",
    "    df_result.loc[index,'label'] = i2c[np.argmax(prob).data.item()]\n",
    "    df_result.loc[index, 'label'] = result[1].item()\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3812\n",
       "1     181\n",
       "4     158\n",
       "2     146\n",
       "3      95\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}, {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.c2i, i2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(f\"{BASE_DIR}/tamil_test_results_ulmfit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 8)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_env",
   "language": "python",
   "name": "temp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
